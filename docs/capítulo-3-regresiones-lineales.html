<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capitulo 3 Capítulo 3: Regresiones lineales | Introducción al uso de machine learning en biología</title>
  <meta name="description" content="Capitulo 3 Capítulo 3: Regresiones lineales | Introducción al uso de machine learning en biología" />
  <meta name="generator" content="bookdown 0.34 and GitBook 2.6.7" />

  <meta property="og:title" content="Capitulo 3 Capítulo 3: Regresiones lineales | Introducción al uso de machine learning en biología" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capitulo 3 Capítulo 3: Regresiones lineales | Introducción al uso de machine learning en biología" />
  
  
  

<meta name="author" content="Jhan C. Salazar y Cristian Román-Palacios" />


<meta name="date" content="2023-08-09" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="qué-es-machine-learning.html"/>
<link rel="next" href="clasificaciones.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">ML y Biologia</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Una introducción breve a Machine Learning</a></li>
<li class="chapter" data-level="2" data-path="qué-es-machine-learning.html"><a href="qué-es-machine-learning.html"><i class="fa fa-check"></i><b>2</b> ¿Qué es Machine Learning?</a>
<ul>
<li class="chapter" data-level="2.1" data-path="qué-es-machine-learning.html"><a href="qué-es-machine-learning.html#tipos-de-machine-learning"><i class="fa fa-check"></i><b>2.1</b> Tipos de machine learning</a></li>
<li class="chapter" data-level="2.2" data-path="qué-es-machine-learning.html"><a href="qué-es-machine-learning.html#definiciones-relevantes-a-machine-learning"><i class="fa fa-check"></i><b>2.2</b> Definiciones relevantes a machine learning</a></li>
<li class="chapter" data-level="2.3" data-path="qué-es-machine-learning.html"><a href="qué-es-machine-learning.html#tipos-de-particiones-de-datos-en-machine-learning"><i class="fa fa-check"></i><b>2.3</b> Tipos de particiones de datos en machine learning</a></li>
<li class="chapter" data-level="2.4" data-path="qué-es-machine-learning.html"><a href="qué-es-machine-learning.html#introducción-a-los-artículos-y-datasets-que-se-usarán-en-este-librillo"><i class="fa fa-check"></i><b>2.4</b> Introducción a los artículos y datasets que se usarán en este librillo</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="capítulo-3-regresiones-lineales.html"><a href="capítulo-3-regresiones-lineales.html"><i class="fa fa-check"></i><b>3</b> Capítulo 3: Regresiones lineales</a>
<ul>
<li class="chapter" data-level="3.1" data-path="capítulo-3-regresiones-lineales.html"><a href="capítulo-3-regresiones-lineales.html#regresión-lineal-univariada"><i class="fa fa-check"></i><b>3.1</b> Regresión lineal univariada</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="capítulo-3-regresiones-lineales.html"><a href="capítulo-3-regresiones-lineales.html#mediciones-de-error-para-regresiones-lineales-univariadas-para-los-coeficientes-y-el-modelo"><i class="fa fa-check"></i><b>3.1.1</b> Mediciones de error para regresiones lineales univariadas para los coeficientes y el modelo</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="capítulo-3-regresiones-lineales.html"><a href="capítulo-3-regresiones-lineales.html#regresión-lineal-de-multiples-variables"><i class="fa fa-check"></i><b>3.2</b> Regresión lineal de multiples variables</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="capítulo-3-regresiones-lineales.html"><a href="capítulo-3-regresiones-lineales.html#mediciones-de-error-para-regresiones-de-multiples-variables-para-los-coeficientes-y-el-modelo"><i class="fa fa-check"></i><b>3.2.1</b> Mediciones de error para regresiones de multiples variables para los coeficientes y el modelo</a></li>
<li class="chapter" data-level="3.2.2" data-path="capítulo-3-regresiones-lineales.html"><a href="capítulo-3-regresiones-lineales.html#interacciones-entre-variables"><i class="fa fa-check"></i><b>3.2.2</b> Interacciones entre variables</a></li>
<li class="chapter" data-level="3.2.3" data-path="capítulo-3-regresiones-lineales.html"><a href="capítulo-3-regresiones-lineales.html#comparaciones-y-decisiones-entre-modelos-de-multiples-variables"><i class="fa fa-check"></i><b>3.2.3</b> Comparaciones y decisiones entre modelos de multiples variables</a></li>
<li class="chapter" data-level="3.2.4" data-path="capítulo-3-regresiones-lineales.html"><a href="capítulo-3-regresiones-lineales.html#asunsiones-y-posibles-problemas-de-las-regresiones-lineales-y-cómo-lidiar-con-ellas"><i class="fa fa-check"></i><b>3.2.4</b> Asunsiones y posibles problemas de las regresiones lineales y cómo lidiar con ellas</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="clasificaciones.html"><a href="clasificaciones.html"><i class="fa fa-check"></i><b>4</b> Clasificaciones</a>
<ul>
<li class="chapter" data-level="4.1" data-path="clasificaciones.html"><a href="clasificaciones.html#regresión-logística"><i class="fa fa-check"></i><b>4.1</b> Regresión logística</a></li>
<li class="chapter" data-level="4.2" data-path="clasificaciones.html"><a href="clasificaciones.html#análisis-discriminante-lineal"><i class="fa fa-check"></i><b>4.2</b> Análisis discriminante lineal</a></li>
<li class="chapter" data-level="4.3" data-path="clasificaciones.html"><a href="clasificaciones.html#comparasión-de-métodos-de-clasificación"><i class="fa fa-check"></i><b>4.3</b> Comparasión de métodos de clasificación</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="métodos-de-remuestreo.html"><a href="métodos-de-remuestreo.html"><i class="fa fa-check"></i><b>5</b> Métodos de remuestreo</a>
<ul>
<li class="chapter" data-level="5.1" data-path="métodos-de-remuestreo.html"><a href="métodos-de-remuestreo.html#validación-cruzada"><i class="fa fa-check"></i><b>5.1</b> Validación cruzada</a></li>
<li class="chapter" data-level="5.2" data-path="métodos-de-remuestreo.html"><a href="métodos-de-remuestreo.html#boopstrap-o-arranque"><i class="fa fa-check"></i><b>5.2</b> Boopstrap (o arranque)</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Publicado con bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introducción al uso de machine learning en biología</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="capítulo-3-regresiones-lineales" class="section level1 hasAnchor" number="3">
<h1><span class="header-section-number">Capitulo 3</span> Capítulo 3: Regresiones lineales<a href="capítulo-3-regresiones-lineales.html#capítulo-3-regresiones-lineales" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Las regresiones lineales estan entre las herramientas más utilizadas para cuantificar la asociacion entre variables o predecir los valores de una respuesta. En esta aproximacion metodologica, la respuesta en el modelo supervisado es continua. Los modelos de regresion lineal son usualmente percibidos como poco flexibles. Sin embargo, estos modelos pueden llegar a incluir niveles de flexibilidad y complejidad comparables con otros modelos usualmente vistos como mas flexibles. Los modelos lineales son un excelente punto de partida para entender métodos más avanzados, ya que, muchos de esos métodos son extensiones o casos especiales de regresiones lineales.</p>
<div id="regresión-lineal-univariada" class="section level2 hasAnchor" number="3.1">
<h2><span class="header-section-number">3.1</span> Regresión lineal univariada<a href="capítulo-3-regresiones-lineales.html#regresión-lineal-univariada" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Este tipo de regresión es potencialmente la más simple que existe. Como su nombre lo indica, la regresion lineal univariada asume que hay una relación lineal entre el predictor <span class="math inline">\(X\)</span> y la variable continua de respuesta <span class="math inline">\(Y\)</span>. Específicamente, este modelo asume que solamente existe una dependencia entre <span class="math inline">\(X\)</span> y <span class="math inline">\(Y\)</span>. Dentro de este paradigma, esta relación se representa con la estructura general:</p>
<p><span class="math display">\[Y ≈ β_{0} + β_{1}X\]</span></p>
<p>En esta ecuacion, <span class="math inline">\(β_{0}\)</span> y <span class="math inline">\(β_{1}\)</span> representan dos parametros: intercepto y la pendiente, respectivamente. En regresiones lineal, el intercepto se refiere a cuando el valor de <span class="math inline">\(x\)</span> es igual a <span class="math inline">\(0\)</span> o <span class="math inline">\(x = 0\)</span>, mientras que pendiente se refiere a al cambio de <span class="math inline">\(y\)</span> por una unidad en el cambio de <span class="math inline">\(x\)</span>; o también se refiere al ángulo de la línea en el plano. Estos parametros deben ser estimados a partir de los datos. En particular, no conocemos cual es el valor real de <span class="math inline">\(β_{0}\)</span> y <span class="math inline">\(β_{1}\)</span>, por ello, tenemos que usar los datos para estimar los coeficientes de acuerdo a el conjunto de datos,</p>
<p><span class="math display">\[(x_1, y_1), (x_2, y_2), … , (x_n, y_n)\]</span></p>
<p>donde <span class="math inline">\(n\)</span> representa los pares de observaciones, que consisten en una medida de <span class="math inline">\(X\)</span> y una de <span class="math inline">\(Y\)</span>, teniendo nuestro objetivo es obtener los coeficientes para <span class="math inline">\(β_{0}\)</span> y <span class="math inline">\(β_{1}\)</span>, asumiendo un ajuste a los datos de acuerdo a,</p>
<p><span class="math display">\[\hat{y} ≈ \hat{β}_{0} + \hat{β}_{1}X_{i}\]</span></p>
<p>La ecuación anterior busca predecir Y en base al valor iésimo de <span class="math inline">\(X\)</span>. Con esto en mente, podemos decir entones que <span class="math inline">\(e_{i} = y_{i} – \hat{y}_{i}\)</span>, lo cual representa el iésimo residual (la diferencia entre el valor observado de <span class="math inline">\(i\)</span> y el valor de <span class="math inline">\(i\)</span> en la respuesta predicha en el modelo lineal). Con todo esto, buscamos encontrar un intercepto <span class="math inline">\(\hat{β}_{0}\)</span> con una pendiente <span class="math inline">\(\hat{β}_{1}\)</span> que resulte en la línea más cerca posible a los datos que utilizamos en nuestro modelo.</p>
<p><strong>Aquí podríamos poner un ejemplo con alguna de las bases de datos que tenemos, y hacer algo similar a lo que hiciste en el capitulo pasado, poner el código de cómo se hace</strong></p>
<div id="mediciones-de-error-para-regresiones-lineales-univariadas-para-los-coeficientes-y-el-modelo" class="section level3 hasAnchor" number="3.1.1">
<h3><span class="header-section-number">3.1.1</span> Mediciones de error para regresiones lineales univariadas para los coeficientes y el modelo<a href="capítulo-3-regresiones-lineales.html#mediciones-de-error-para-regresiones-lineales-univariadas-para-los-coeficientes-y-el-modelo" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Anteriormente vimos, que lo que buscamos en una regresión lineal es encontrar los puntos que sean lo más cercano posibles a nuestro modelo de interes. Hay muchas maneras de buscar la cercanía de estos puntos, uno de los métodos más usados es conocido como mínimos cuadrados. Con esto en mente, podemos definir la suma de los cuadrados del error residual (SCE o RSS – residual sum of squares – aquí lo vamos a llamar RSS), como</p>
<p><span class="math display">\[RSS = e_{1}^{2} + e_{2}^{2} +⋯+ e_{n}^{2}\]</span></p>
<p>La cual equivale a</p>
<p><span class="math display">\[RSS=[(y_{1}-\hat{β}_{0}-\hat{β}_{1}x_{1})]^{2}+[(y_{2}-\hat{β}_{0}-\hat{β}_{1}x_{2})]^{2}+⋯+[(y_{n}-\hat{β}_{0}-\hat{β}_{1}x_{n})]^{2}\]</span></p>
<p>Usualmente utilizamos RSS para determinar la proporción de la variación total que es explicada por el modelo de regresión (<span class="math inline">\(R^{2}\)</span> o coeficiente de determinación – vamos a hablar de esto un poco más adelante).</p>
<p>Cuando trabajamos con funciones, asumimos que la relación mas cerca a la realidad tiene un termino de error, dado esto nuestra ecuación lineal estaría dada por:</p>
<p><span class="math display">\[Y ≈ β_{0} + β_{1}X + ε\]</span></p>
<p>Para recapitular, <span class="math inline">\(β_{0}\)</span> es el intercepto, el cual se refiere al valor de <span class="math inline">\(Y\)</span> cuando <span class="math inline">\(X = 0\)</span>, <span class="math inline">\(β_{1}\)</span> es la pendiente, que hace referencia al incremento de Y que está asociado con el cambio de una unidad de <span class="math inline">\(X\)</span> mientras que el valor de <span class="math inline">\(ε\)</span> es el error que está presente cuando se corre este modelo lineal.</p>
<p>Algo que no hemos mencionado hasta ahora, es que, posiblemente, una verdadera relación nunca es linear, porque puede haber otras variables que causan que haya variación en <span class="math inline">\(Y\)</span>. Por ello, la ecuación que mostramos anterior mente es la mejor aproximación lineal para encontrar la verdadera relación entre <span class="math inline">\(X\)</span> y <span class="math inline">\(Y\)</span>.Esto quiere decir que podemos en la vida real solo podemos computar la línea de los mínimos cuadra (estimados de coeficiente de mínimos cuadrados; ver siguiente ecuación), dado que no podemos ver la línea de regresión para toda la población.</p>
<p><span class="math display">\[\hatβ_{1} = \frac{\sum_{i = 1}^{n}(x_{i} - \overline{x})(y_{i} - \overline{y})}{\sum_{i = 1}^{n}(x_{i} - \overline{x})^{2}}\]</span>,</p>
<p><span class="math display">\[\hatβ_{0} = \overline{y} - \hatβ_{1}\overline{x}\]</span></p>
<p>Donde <span class="math inline">\(\overline{y} ≡ \frac{1}{n}\sum_{i = 1}^{n}y_{i}\)</span> and <span class="math inline">\(\overline{x} ≡ \frac{1}{n}\sum_{i = 1}^{n}x_{i}\)</span> (<span class="math inline">\(≡\)</span> significa <em>equivalente a</em>) son solamente medias. En otros palabras, buscamos estimar dos coeficientes desconocidos usando <span class="math inline">\(β_{0}\)</span> y <span class="math inline">\(β_{1}\)</span>, los cuales definen la línea de cadrados mínimos. <em>Nota: si vemos con detenimiente esta ecuación, es una simplificación de la ecuación de RSS</em>.</p>
<p>Otra variable a tener en cuenta cuando estemos haciendo nuestros análisis es <span class="math inline">\(\mu\)</span> o la media, la cual es desconocida, pero tenemos la media para nuestra muestra, también conocido como media de la muestra <span class="math inline">\(\hat{\mu}\)</span>, la cual puede ser estimada como <span class="math inline">\(\hat{\mu} = \overline{y}\)</span> donde <span class="math inline">\(\overline{y} = \frac{1}{n}\sum_{i = 1}^{n}y_{i}\)</span>.Para saber que tan precisa es la media de la muestra con respecto a la media global podemos estimar el error estándar de <span class="math inline">\(\hat{\mu}\)</span>, que se puede representar como <span class="math inline">\(SE(\hat{\mu})\)</span>, cuya formula es</p>
<p><span class="math display">\[Var(\hat{\mu}) = SE(\hat{\mu})^{2} = \frac{\delta^{2}}{n}\]</span>,</p>
<p>Donde <span class="math inline">\(\delta\)</span> es la desviación estándar para cada uno de los valores de <span class="math inline">\(y_{i}\)</span> de <span class="math inline">\(Y\)</span>. Igualmente, <span class="math inline">\(\delta^{2}\)</span> hace referencia a la varianza del error, para esto tenemos que asumir que el error <span class="math inline">\(ε_{i}\)</span> de cada observación están no correlacionados, es decir, <span class="math inline">\(\delta^{2} = Var(ε)\)</span>. Generalmente, <span class="math inline">\(\delta^{2}\)</span> es desconocida, pero podemos estimar el error estánadar de los residuos o RSE (por ssus siglas en inglés <em>residual standard error</em>), para esto usamos la siguiente formula, <span class="math inline">\(RSE = \sqrt{RSS/(n - 2)}\)</span>.</p>
<p>Ya teniendo el error estándar, podemos estimar el intervalo de confianza, el cual se refiere al rango de valores que tienen un 95% de probabilidad de ser estimado, dentro de este rango se encuentra el valor que no conocemos para nuestro parámetro de interes. Para un regresión lineal, el 95% del intervalo de confianza de <span class="math inline">\(\hatβ_{1}\)</span> está dado por,</p>
<p><span class="math display">\[\hatβ_{1} ± 2 ⋅ SE(\hatβ_{1})\]</span></p>
<p><span class="math display">\[[\hatβ_{1} - 2 ⋅ SE(\hatβ_{1})]  ,  [\hatβ_{1} + 2 ⋅ SE(\hatβ_{1})]\]</span></p>
<p>Igualmente, para el intervalo de confianza de <span class="math inline">\(\hatβ_{0}\)</span>, esta dado por una ecuación similar,</p>
<p><span class="math display">\[\hatβ_{0} ± 2 ⋅ SE(\hatβ_{0})\]</span></p>
<p>Cuando tenemos el error estándar, también podemos probar hipótesis en los coeficientes. Las hipótesis que usualmente probamos son: la <strong>hipótesis nula</strong></p>
<p><span class="math inline">\(H_{0}: No hay relación entre X y Y\)</span></p>
<p>Mientras que la <strong>hipótesis alternativa</strong> sería</p>
<p><span class="math inline">\(H_{\alpha}: No hay relación entre X y Y\)</span></p>
<p>Matemáticamente hablando, la denotación para estas dos hipótesis sería:</p>
<p><span class="math display">\[H_{0}: \hatβ_{0} = 0\]</span></p>
<p>Y</p>
<p><span class="math display">\[H_{\alpha}: \hatβ_{1} = 0\]</span></p>
<p><strong>el estadistico t y sus hipotesis, y R2</strong></p>
</div>
</div>
<div id="regresión-lineal-de-multiples-variables" class="section level2 hasAnchor" number="3.2">
<h2><span class="header-section-number">3.2</span> Regresión lineal de multiples variables<a href="capítulo-3-regresiones-lineales.html#regresión-lineal-de-multiples-variables" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>En la vida real, usualmente las respuestas a predicciones están dadas por más de un predictor.</p>
<p><span class="math display">\[Y ≈ β_{0} + β_{1}X_{1} + β_{2}X_{2} + … + β_{n}X_{n} + ε\]</span></p>
<p><strong>Acá podemos seguir hablando de manera general sobre la matematica detrás de las regresiones lineales de varias variables, y al final del parrafo hacer un ejemplo con alguna de las bases de datos que tenemos</strong></p>
<div id="mediciones-de-error-para-regresiones-de-multiples-variables-para-los-coeficientes-y-el-modelo" class="section level3 hasAnchor" number="3.2.1">
<h3><span class="header-section-number">3.2.1</span> Mediciones de error para regresiones de multiples variables para los coeficientes y el modelo<a href="capítulo-3-regresiones-lineales.html#mediciones-de-error-para-regresiones-de-multiples-variables-para-los-coeficientes-y-el-modelo" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Hablar de RSS, el estadistico F y las hipotesis, RSE</p>
</div>
<div id="interacciones-entre-variables" class="section level3 hasAnchor" number="3.2.2">
<h3><span class="header-section-number">3.2.2</span> Interacciones entre variables<a href="capítulo-3-regresiones-lineales.html#interacciones-entre-variables" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Usar una de las bases de datos para ejemplificar esto. Hablar sobre como los resultados pueden cambiar cuando se usar una o varias variables; discutir esto cuando se tienen las interacciones y cuando no se tienen encuenta.</p>
</div>
<div id="comparaciones-y-decisiones-entre-modelos-de-multiples-variables" class="section level3 hasAnchor" number="3.2.3">
<h3><span class="header-section-number">3.2.3</span> Comparaciones y decisiones entre modelos de multiples variables<a href="capítulo-3-regresiones-lineales.html#comparaciones-y-decisiones-entre-modelos-de-multiples-variables" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Hablar del valor p -y tal vez por qué se usa. Introducir a metodos para decidir cual es el mejor modelo (AICc, AIC, BIC, adjusted R2, Mallow’s C), aunque creo que esto lo vamos expandir mas un poco mas adelante.Hablar sobre seleccion de varibles: seleccion hacia adelante, seleccion desde atras, seleccion mixta.</p>
</div>
<div id="asunsiones-y-posibles-problemas-de-las-regresiones-lineales-y-cómo-lidiar-con-ellas" class="section level3 hasAnchor" number="3.2.4">
<h3><span class="header-section-number">3.2.4</span> Asunsiones y posibles problemas de las regresiones lineales y cómo lidiar con ellas<a href="capítulo-3-regresiones-lineales.html#asunsiones-y-posibles-problemas-de-las-regresiones-lineales-y-cómo-lidiar-con-ellas" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Hablar sobre no linearidad, correlaciones de los errores, variancia no constante en el error, datos atipicos, Punto de alto apalancamiento (high-leverage) y colinearidad. Podriamos mostrar ejemplos a acá tambien.</p>
<ul>
<li><p>Definiciones generales (teorico):
– Simple
– Multiple
— Distinguir de multivariada
– Asunciones
– Confounders (factores de confusion: En el libro no lo explican si no hasta que se abran de Clasificaciones)
– Interacciones
– data augmentation (Este no lo hablan el cap de regresiones)
– Mediciones de error (RMSE; MSE; MAE; etc)
– Comparaciones multimodelo (AIC, AICc, BIC)</p></li>
<li><p>Implementacion (codigo y explicacion):
– Ejemplo de reg simple
– Ejemplo de reg multiple
– Data augmentation
— Mediciones de error y comparacion multimodelo</p></li>
</ul>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="qué-es-machine-learning.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="clasificaciones.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/RomanPalacios-lab/ml-biologia/edit/main/03-ols.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/RomanPalacios-lab/ml-biologia/blob/main/03-ols.Rmd",
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
