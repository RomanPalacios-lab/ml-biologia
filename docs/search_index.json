[["index.html", "Introducción al uso de machine learning en biología Capitulo 1 Una introducción breve a Machine Learning", " Introducción al uso de machine learning en biología Jhan C. Salazar y Cristian Román-Palacios 2023-08-19 Capitulo 1 Una introducción breve a Machine Learning El machine learning es una de las herramientas que más se aplica en diferentes partes de nuestra vida diaria. Por ejemplo, los mecanismos de predicción de palabras en su celular, detección de spam en el correo, predicciones de estado del tiempo, entre otros, estan cercanamente relacionados con procesos incluidos en machine learning. Sin embargo, muy pocas personas conocen cómo utilizar perspectivas de machine learning, ya sea por miedo o desconocimiento a la programación, o simplemente, porque mucha de la información se encuentra en otro idioma, usualmente, en inglés. Con este libro, buscamos dar una breve introducción al machine learning y su aplicación en el idioma español, con ejemplos en analisis de datos biologicos. Como aclaración, el que los ejemplos que se usaran a lo largo del libro estaran enfocados en investigaciones recientes en biológia no significa que no puedan ser aplicados a otras áreas de estudio. Este libro va dirigido a todas las personas interesadas en aprender a usar machine learning en su investigaciones, sin importar en que niveles de su formación académica se encuentren o que trabajen en la academio o en la indrustria. Este documento está pensado para lectores que tengan o no conocimiento previo en programación. El foco principal de este libro no es sólo enseñar cómo utilizar y entender qué es machine learning, si no hacer accesible su uso para personas de habla hispana. Este libro inicia con una introducción a machine learning, pasa por regresiones lineales, aspectos de clasificación, y termina con introducciones cortas a modelos alternativos y más complejos de regresión y clasificación. Cada uno de los capítulos revisa tando el componente práctico como el teórico del tema principal a tratar. La discusión teórica incluye detalles generales sobre la fundamentación de algoritmos y su uso en diferentes contextos. La implementación práctica incluye estudios de casos basados en publicaciones recientes por autores latinoamericanos. En general, este libro pretende una exposición tanto a aspectos generales de machine learning en su teoría y práctica, así como también al uso directo en el análisis de datos biológicos. Existe una variedad de lenguajes de programación que permiten implementar algoritmos de machine learning. En general, el componente práctico de este libro estará enfocado en ilustrar el uso de esta perspectiva analitica utilizando el lenguaje de programacion R. Esta herramientas es de código abierto, gratuita, y tiene asociada una amplia red de usuarios y desarrolladores que se encuentran en constante interacción y producción de conocimiento. Como alternativa R están python, julia, matlab, entre otros. Estos lenguages también permiten el análisis de datos en una aproximación de machine learning y son alternativas ideales para quienes tengan intenciones de explorar de forma práctica el componente teórico de este documento. Sin embargo, para quienes consultan el libro y no tienen experiencia en programación en R, el primer capitulo se enfoca en introducir R como el lenguaje para usos subsecuentes en los componentes prácticos del documento. Además de nuestro libro, existen diferentes recursos en español que tratan diferentes aspectos de machine learning en R y otros languajes de programación. Por ejemplo, en su libro, Rafael A. Irizarry da una breve introduccion a R en el contexto de ciencia de datos. R Para ciencia de datos, traducido del inglés, también es un excelente recurso introductorio tanto a R como a machine learning. Aunque estos recursos (y otros) se enuentran en español, los documentos existentes son (1) traducciones literales a textos originalmente escritos en inglés, (2) tienen poco enfasis en machine learning por ser pensados en el contexto de data science, o (3) no tienen una aplicacion directa en biologia. Por lo tanto, con este documento propendemos a integrar aspectos básicos de machine learning en el contexto actual de biología latinoamericana, mientras resaltamos el trabajo investigativo en la región. "],["qué-es-machine-learning.html", "Capitulo 2 ¿Qué es Machine Learning? 2.1 Tipos de machine learning 2.2 Definiciones relevantes a machine learning 2.3 Tipos de particiones de datos en machine learning 2.4 Introducción a los artículos y datasets que se usarán en este librillo", " Capitulo 2 ¿Qué es Machine Learning? El enfoque principal de este libro es exponer el uso de herramientas de machine learning para responder preguntar en biología. Sin embargo, aún no se ha definido formalmente que es machine learning. En pocas palabras, machine learning se refiere al uso de análisis estadísticos para hacer predicciones o inferencias sobre un problema en particular utilizando particiones específicas del conjunto de datos. Por lo tanto, el aspecto clave que distingue en general la práctica de machine learning respecta al uso de secciones de los datos con el objetivo de describir explícita y finamente el comportamiento y la generalización de los modelos. Actualmente, las aplicaciones de machine learning se encuentran varios ámbitos demuestra vida diaria. Por ejemplo, cuando hablamos a nuestro celular para interactuar con Alexa (Amazon), Siri (Apple) o Google Maps, modelos entrenados utilizando un paradigma de machine learning permite que aquellas palabras que enunciamos sean interpretadas por el equipo (e.g., celular, computador) tras algunos pasos de codificación (e.g., creacion de matrices). Igualmente, Google Maps colecta datos de tráfico desde el punto en el que estamos al sitio en donde vamos para encontrar la ruta más rápido al lugar de destino. Como optimizar estas rutas tambien puede ser una tarea de machine learning. Así como estos ejemplos, hay cientos de situaciones que pueden ser usadas para ejemplificar el uso de machine learning en nuestra cotidianidad. 2.1 Tipos de machine learning Dentro del machine learning, los problemas estadísticos generalmente se dividen en dos categorías principales: supervisadas y no supervisadas. La primera categoría, la supevisada, se refiere a que por cada observación del predictor (\\(x\\)), hay una medida de respuesta (\\(y\\)). Por el contrario, la categoría no supervisada hace referencia a que el predictor (x) no está asociado a una respuesta (y) - no tenemos una variable respuesta que pueda supervisar nuestro análisis. A lo largo del libro nos vamos a enfocar principalmente en la categoría de aprendizaje supervisado. Por otro lado, tambien se resalta que existen otras alternativas de aprendijaze en este tipo de sistemas (e.g. aprendizaje de refuerzo). Sin embargo, la ubicacion de estas aproximaciones es un poco mas ambigua con respecto a las dos principales discutidas en esta seccion. data &lt;- tibble::tibble(from = c(&quot;Machine Learning&quot;, &quot;Machine Learning&quot;, &quot;Supervised Learning&quot;, &quot;Supervised Learning&quot;, &quot;Unsupervised Learning&quot;, &quot;Unsupervised Learning&quot;), to = c(&quot;Supervised Learning&quot;, &quot;Unsupervised Learning&quot;, &quot;Classification&quot;, &quot;Regression&quot;, &quot;Clustering&quot;, &quot;Dimensionality reduction&quot;)) ggflowchart(data) 2.2 Definiciones relevantes a machine learning Al momento de utilizar modelos de machine learning debemos tener en cuenta que hay compromisos (conocidos como trade-offs en inglés). Este es el caso para la relación entre el trío de conceptos clave flexibilidad-interpretabilidad-complejidad. Entender la interacción de estos tres elementos juega un papel clave en la descripción de la generalización relativa de modelos y la definición de que tan apropiados son de acuerdo a las necesidades prácticas del investigador. Primero, la flexibilidad hace referencia a cuanto las características de los datos influencia al modelo, dado esto, algunos modelos lineales son más flexibles que otros. Por lo tanto, modelos más flexibles pueden ajustarse más cercanamente a los datos que funciones inflexibles. Sin embargo, la descripción muy ajustada de un modelo a un conjunto de datos puede implicar para este mismo modelo la incapacidad de generalización en otros conjuntos de datos. Es entonces importante considerar la necesidad de describir cercanamente un conjunto de datos sin dejar a un lado el objetivo amplio de generar modelos que permitan interpretar patrones en datos que aun no se examinan (i.e., generalización). Segundo, la interpretabilidad de un model se refiere a lo fácil o difícil que es entender como las variables influencian el resultado. En un sentido amplio, se puede decir que modelos más inflexibles son mas interpretables. La flexibilidad de un modelo tiende a aumentar a medida que la interpretabilidad disminuye. Por lo tanto, modelos más complejos tienden a no ser tan facilmente interpretables. Si el objetivo de quien analiza los datos es entender que predictores influencia la respuesta (e.g. analisis supervisados), modelos mas inflexibles (y por lo tanto menos complejos) son en general preferidos. Tercero, la complejidad hacer referencia tanto a la estructura de los modelos (e.g. cajas negras) como al número de parametros que se usan en un modelo determinado. Tener en cuenta los compromisos que ocurren entre flexibilidad, interpretabilidad y complejidad es central para entender patrones generales de seleccion de modelos dentro de un contexto de machine learning. Otros tres conceptos para tener en cuenta cuando se usan modelos de machine learning son la varianza, el ruido, y el sesgo. Primero, la varianza hace referencia a la variacion intrinseca a generar predicciones con modelos. Por ejemplo, models inflexibles tienden a generar predicciones que son consistentes entre si (modelo relativamente con poca varianza). Modelos mas complejos tienden a producir predicciones mas discimiles entre si (modelo relativamente con alta varianza). Segundo, el ruido esta asociado a la variacion intrinseca a la variable de respuesta. Este aspecto es independiente al modelo y tiene en general mas relacion con errores de medicion que con otro aspecto. Tercero, el sesgo se refiere al error que se da a causa por aproximar un problema de la vida real, teniendo en cuenta el ruido. El sesgo es por lo tanto la relacion (i.e. diferencia) entre varianza y ruido. Este aspecto es relevante dado que los modelos son simplificaciones de datos y, aunque pueden estar cercanos a la realidad, siempre tendran limitaciones para llegar al modelo subyacente. Otro concepto para tomar en cuenta cuando se esta eligiendo el método de aprendizaje estadístico es la maldición de la dimensionalidad. Este patron se refiere a los problemas que se dan a causa del aumento de variables independientes cuando en un set de datos. Debido a que al aumentar el número de dimensionas al modelo le toma más tiempo al modelo para computar el método de aprendizaje. Subajuste y sobreajuste son otros conceptos para tomar en cuenta al momento de elegir nuestro método de aprendizaje. El subajuste hace referencia cuando el error del set de datos de entrenamiento es grande, mientras que es dice que uno modelos está sobreajustado cuando el error del set de datos de entrenamiento es bajo. En donde el promedio del error es el resultado del uso del método de aprendizaje estadístico para predecir la respuesta de una nueva observación. Nota: usualmente, modelos muy complejos pueden causar que es modelo este sobreajustado. Al momento de elegir nuestro modelo de aprendizaje debemos de tener en cuenta dos tipos de errores, errores de entrenamiento y errores de prueba. Los errores de entrenamiento hacen referencia al error de los datos de entrenamiento, mientras que el error de prueba está asociado con el set observaciones. Algo que hay que tener en cuenta es que para las regresiones lineales y para las clasificaciones, no hay una relación entre el error de entrenamiento y el error de prueba. x = seq(0,5,length.out=6) y = -x label = c(&quot;Linear regression&quot;, &quot;Decision tree&quot;, &quot;K-nearest neightbors&quot;, &quot;Random Forest&quot;, &quot;Support Vector Machines&quot;, &quot;Neural Nets&quot;) data &lt;- cbind.data.frame(x, y, label) ggplot(data, aes(x = x, y = y, label = label)) + geom_text() 2.3 Tipos de particiones de datos en machine learning El aprendizaje de maquina es de alguna forma el resultado del uso consciente de la informacion disponible, generalmente en forma tabular. En este campo, existen dos tipos de grupos de datos. Cada uno de estos deriva directamente de los datos totales colectados durante procesos investigativos. Primero, el conjunto de datos de entrenamiento, referido en ingles como train set, se usa en general para que el o los modelos puedan patrones que estan posiblemente presentes en los datos. Este conjunto de datos usualmente representa el 70% u 80% de los datos originales. Segundo, el conjunto de datos de prueba, tambien mencionado como test set en ingles, se usa para examinar la capacidad de generalizacion en el aprendizaje inicial llevado a cabo en el conjunto de datos de entrenamiento. Este conjunto de datos representa usualmente el resto de la informacion que no se ha usado en el conjunto de datos de prueba. En pocas palabras, primero se entrena el modelo en el conjunto de datos de entrenamiento y despues de evalua su desempeño en el conjunto de datos de prueba. Estos conjuntos de datos tienen que ser conservados de forma independiente desde el principio de los analisis. Especificamente, el conjunto de datos de prueba tiene que servir como una fuente independiente de verificacion de que los patrones en el conjunto de datos de entrenamiento pueden extenderse a otros conjuntos de datos. Si se mezcla informacion entre estos conjuntos (fuga de datos o data leakeage), se pierde el sentido de este particionado. Existen otros tipos de particiones de los conjuntos de datos de entrenamiento y prueba. Sin embargo estos dos conjuntos son los mas relevantes en muchos sentidos para el campo. Otras particiones (e.g. validacion) seran discutidas en capitulos subsecuentes cuando se revise el re-muestreo. 2.4 Introducción a los artículos y datasets que se usarán en este librillo A lo largo de este librillo vamos a ilustrar ejemplos del uso de los diferentes métodos de aprendizaje estadístico utilizando set de datos que están publicados y disponibles para el público. Vamos a utilizar tres diferentes sets de datos el primero es un artículo liderado por Juan Carlos Copete y colaboradores, el cual está enfocado en entender la diversidad de comunidades de palmas en el Chocó biográficos. El segundo, fue liderado por Gustavo A. Londoño y colaboradores, en el cual este grupo de científicos buscaba entender los patrones de depredación de nidos en montañas del trópico. Por último, la tercera base de datos que vamos a usar fue liderada por Giovanny Ramirez y Jesus Orlando Rangel, en la cual estos investigadores buscaban entender la sucesión de plantas en un bosque del Chocó beogeográfico. Al final de cada uno de los capítulos vamos a tener ejemplos de cómo correr los diferentes análisis que se explican en el software R. El artículo que vamos a usar para los ejemplos de machine learning tiene como título “Diversidad de comunidades de palmas en el Chocó biogeográfico y su relación con la precipitación”. En este artículo los autores utilizan datos de precipitación en 48 transectos en comunidades de palmas a lo largo del Chocó biogeográfico en 4 localidades en Colombia y Ecuador. Para esto, Juan Carlos Copete y colaboradores tomaron datos de precipitación promedio anual, número promedio de individuos por transecto, número de especies y promedio de especies por transecto. Esto con el fin de responder a la pregunta de que si existe una relación entre la riqueza y abundancia de palmas en el Chocó biogeográfico. En resumen, los autores encontraron que una que diversidad de palmas está influenciada por la precipitación, mientras que la abundancia esta negativamente influenciada por la precipitación, en donde solo una especie – no muy abundantes – pueden sobrevivir en lugares muy húmedo. El segundo artículo que vamos a usar lleva como título “Changing patterns of nest predation and predator communities along a tropical elevation gradient” o “Patrones cambiantes de depredación de nidos y comunidades de depredadores a lo largo de un gradiente de elevación tropical” en español liderado por Gustavo A. Londoño y colaboradores. En este estudio los autores querían investigar si había cambios en los patrones y tipos de depredadores a lo largo de un gradiente altitudinal en bosque de Perú. Para esto, los autores utilizaron información sobre 2538 nidos que fueron monitoreados en el transcurso de seis años, desde el 2008 hasta el 2016. Además, durante ese mismo tiempo se tomaron fotografías y videos para cada uno de los nidos de los cuales 338 se tenía información de depredación. Igualmente, se tomaron datos de nido y composición del nido (si tenía huevos o polluelos). Los autores encontraron que a medida que la elevación aumenta la presión de depredación disminuye y l tipo de depredadores también cambia. Por último, Giovanny Ramirez y Jesus Orlando Rangel realizaron un estudio titulado “Sucesión vegetal en áreas de minería a cielo abierto en el bosque pluvial tropical del departamento del Chocó, Colombia”. En este estudio los autores se enfocaron en caracterizar comunidades vegetales en minas que han sido abandonadas en diferentes tiempos (30, 15 y 5 años de abandono) con el fin de ver como patrones de abundancia y diversidad cambian con el tiempo de recuperación en el municipio de Condoto en Chocó. Para esto, se midió la altura de la vegetación y se identificaron las especies presentes en cada sitio de muestreo, además de medir la abundancia relativa de especies y la frecuencia de especies. Los autores encontraron que la riqueza, mientras que la abundancia disminuye ha medida que el tiempo de recuperación aumenta (30 años -&gt; 15 años -&gt; 5 años). Esquemas: – Diagrama de supervisado vs no supervisado (Ok) – Esquema conceptual complejidad vs interpretabilidad (Ok) – Diagrama de tejo (TBD) – Maldicion de la dimensionalidad (TBD) – Todavía sigo buscando uno para regresión lineal, los que estan ahora son los de habíamos dicho al principi "],["regresiones-lineales.html", "Capitulo 3 Regresiones lineales 3.1 Regresión lineal univariada 3.2 Regresión lineal de multiples variables", " Capitulo 3 Regresiones lineales Las regresiones lineales estan entre las herramientas más utilizadas para cuantificar y describir la asociacion entre variables o predecir los valores de una respuesta. En esta aproximacion metodologica, la respuesta en el modelo supervisado es continua. Los modelos de regresion lineal son usualmente percibidos como poco flexibles. Sin embargo, estos modelos pueden llegar a incluir niveles de flexibilidad y complejidad comparables con otros modelos usualmente vistos como mas flexibles. Los modelos lineales son un excelente punto de partida para entender métodos más avanzados, ya que, muchos de esos métodos son extensiones o casos especiales de regresiones lineales. 3.1 Regresión lineal univariada Este tipo de regresión es potencialmente la más simple que existe en su estructura. La regresion lineal univariada asume que hay una relación lineal entre el predictor \\(X\\) y la variable continua de respuesta \\(Y\\). Específicamente, este modelo asume que unicamente existe una dependencia entre \\(X\\) y \\(Y\\). Dentro de este paradigma, esta relación se representa como: \\[Y ≈ β_{0} + β_{1}X\\] En esta ecuacion, \\(β_{0}\\) y \\(β_{1}\\) representan dos parametros: intercepto y la pendiente, respectivamente. El intercepto se refiere al valor en el cual \\(x\\) es igual a \\(0\\), \\(x = 0\\). La pendiente se refiere a al cambio de \\(y\\) por una unidad en el cambio de \\(x\\). Es entonces el ángulo de la línea en el plano. Estos parametros deben ser estimados a partir de los datos, \\[(x_1, y_1), (x_2, y_2), … , (x_n, y_n)\\] donde \\(n\\) representa los pares de observaciones en el conjunto de datos, que consisten en una medida de \\(X\\) y una de \\(Y\\). Teniendo en cuenta que nuestro objetivo es el obtener los coeficientes para \\(β_{0}\\) y \\(β_{1}\\), asumiendo un ajuste a los datos de acuerdo a, \\[\\hat{y} ≈ \\hat{β}_{0} + \\hat{β}_{1}X_{i}\\] La ecuación anterior busca predecir \\(Y\\) en base al valor iésimo de \\(X\\). Con esto en mente, podemos decir entones que \\(e_{i} = y_{i} - \\hat{y}_{i}\\) es entonces la diferencia entre el valor real de cada observacion en el conjunto de datos (\\(y_{i}\\)) y el aproximado por el modelo (\\(\\hat{y}_{i}\\)). Esta diferencia es conocida como residual e identifica el ajuste del modelo con los datos. Conociendo entonces la desviacion que existe entre los valores generados por el modelo y los datos colectados, podemos entonces enfocarnos en minimizar el error (e.g. residuales) a partir de cambios en los valores de los parametros \\(\\hat{β}_{0}\\) y \\(\\hat{β}_{1}\\). 3.1.1 Mediciones de error para regresiones lineales univariadas para los coeficientes y el modelo Lo que buscamos en una regresión lineal es ajustar un modelo donde se cometa el minimo error con respecto a los datos existentes. Hay muchas maneras de buscar la cercanía de estos puntos (i.e. los del modelo y las observaciones). Uno de los métodos más usados es conocido como mínimos cuadrados. Con esto en mente, podemos definir la suma de los cuadrados del error residual (SCE o RSS, residual sum of squares), como: \\[RSS = e_{1}^{2} + e_{2}^{2} +⋯+ e_{n}^{2}\\] La cual equivale a la suma a lo largo de todas las observaciones en el set de datos de los residuales al cuadrado: \\[RSS=[(y_{1}-\\hat{β}_{0}-\\hat{β}_{1}x_{1})]^{2}+[(y_{2}-\\hat{β}_{0}-\\hat{β}_{1}x_{2})]^{2}+⋯+[(y_{n}-\\hat{β}_{0}-\\hat{β}_{1}x_{n})]^{2}\\] Usualmente utilizamos RSS para determinar la proporción de la variación total que es explicada por el modelo de regresión (\\(R^{2}\\) o coeficiente de determinación – vamos a hablar de esto un poco más adelante). Tambien notamos que cuando trabajamos con funciones se asume que la relación mas cerca a la realidad tiene un termino de error (\\(ε\\)). Dado esto nuestra ecuación lineal estaría dada en realidad por la estructura, \\[Y ≈ β_{0} + β_{1}X + ε\\] Hasta el momento hemos descrito patrones lineales en el set de datos. Sin embargo, los modelos que subyacen datos reales raramente son lineales. Esto es debido a complejidad adicional, donde variables externas pueden generar efectos sobre la estructura de relacion entre las variables focales. Por ello, la ecuación que mostramos anteriormente es la mejor aproximación lineal para encontrar la relación entre \\(X\\) y \\(Y\\). Esto implica que, dado los coeficientes del modelo son desconocidos en datos experimentales, solo podemos estimar estos parametros a partir de aproximaciones como las de minimos cuadrados, \\[\\hatβ_{1} = \\frac{\\sum_{i = 1}^{n}(x_{i} - \\overline{x})(y_{i} - \\overline{y})}{\\sum_{i = 1}^{n}(x_{i} - \\overline{x})^{2}}\\], \\[\\hatβ_{0} = \\overline{y} - \\hatβ_{1}\\overline{x}\\] Donde \\(\\overline{y} ≡ \\frac{1}{n}\\sum_{i = 1}^{n}y_{i}\\) y \\(\\overline{x} ≡ \\frac{1}{n}\\sum_{i = 1}^{n}x_{i}\\) (\\(≡\\) significa equivalente a) son medias. Por lo tanto, lo que se busca es estimar dos coeficientes desconocidos usando \\(β_{0}\\) y \\(β_{1}\\), los cuales definen directamente la línea a partir de la aproximacion de minimos cuadrados. Nota: si vemos con detenimiente esta ecuación, es una simplificación de la ecuación de RSS. Otra variable a tener en cuenta cuando estemos haciendo nuestros análisis es \\(\\mu\\) o la media. Este parametro, el cual es desconocido, puede ser aproximado a partir de la media para nuestra muestra, \\(\\hat{\\mu} = \\overline{y}\\) donde \\(\\overline{y} = \\frac{1}{n}\\sum_{i = 1}^{n}y_{i}\\). Para saber que tan precisa es la media de la muestra con respecto a la media global podemos estimar el error estándar de \\(\\hat{\\mu}\\), que se puede representar como \\(SE(\\hat{\\mu})\\), cuya formula es \\[Var(\\hat{\\mu}) = SE(\\hat{\\mu})^{2} = \\frac{\\delta^{2}}{n}\\], Donde \\(\\delta\\) es la desviación estándar para cada uno de los valores de \\(y_{i}\\) de \\(Y\\). Igualmente, \\(\\delta^{2}\\) hace referencia a la varianza del error. Para esto tenemos que asumir que el error \\(ε_{i}\\) de cada observación están no correlacionados, es decir, \\(\\delta^{2} = Var(ε)\\). Generalmente, \\(\\delta^{2}\\) es desconocida, pero podemos estimar el error estánadar de los residuos o RSE (por sus siglas en inglés residual standard error), para esto usamos la siguiente formula, $\\(RSE = \\sqrt{RSS/(n - 2)}\\) Ya teniendo el error estándar, podemos estimar el intervalo de confianza (e.g. 95%). Dentro de este rango se encuentra el valor que no conocemos para nuestro parámetro de interes con el valor definido de confianza. Para un regresión lineal, el 95% del intervalo de confianza de \\(\\hatβ_{1}\\) está dado por, \\[\\hatβ_{1} ± 2 ⋅ SE(\\hatβ_{1})\\] \\[[\\hatβ_{1} - 2 ⋅ SE(\\hatβ_{1})] , [\\hatβ_{1} + 2 ⋅ SE(\\hatβ_{1})]\\] Igualmente, el intervalo de confianza de \\(\\hatβ_{0}\\), esta dado por una ecuación similar: \\[\\hatβ_{0} ± 2 ⋅ SE(\\hatβ_{0})\\] Tras estimar el error estandard en los parametros, podemos consider probar hipótesis en los coeficientes. La hipótesis que usualmente probamos contrastamos es la hipótesis nula que establece, \\(H_{0}\\): No hay relación entre \\(X\\) y \\(Y\\) Mientras que la hipótesis alternativa indica que, \\(H_{\\alpha}\\): Hay relación entre \\(X\\) y \\(Y\\) Matemáticamente hablando, la denotación para estas dos hipótesis sería respectivamente: \\[H_{0}: \\hatβ_{0} = 0\\] Y \\[H_{\\alpha}: \\hatβ_{1} ≠ 0\\] La pregunta que queda ahora es ¿cómo probamos (rechazamos o no) la hipótesis nula?. Para este tenemos que determinar que tan alejado \\(\\hatβ_{1}\\), la pendiente, está de un valor de 0. Para esto utilizamos el estadístico t: \\[t = \\frac{\\hatβ_{1} - 0}{SE(\\hatβ_{1})}\\], Este estadístico mide el número de desvaciones estándar en el que \\(\\hatβ_{1}\\) se aleja de 0. Por lo tanto, valores pequeños de \\(\\hatβ_{1}\\) dan evidencia de que \\(\\hatβ_{1} ≠ 0\\), es decir hay una relación estadistica entre \\(X\\) y \\(Y\\). Cuando \\(\\hatβ_{1}\\) tiene valores absolutos muchos más grande, se rechaza la hipótesis nula. Es relativamente sencillo computar la probabilidad de observar un valor de \\(|t|\\) o mayor, cuando asumimos que \\(\\hatβ_{1} = 0\\). A esta probabilidad se le conoce normalmente como valor-p. Cuando el valor de p es muy pequeño (e.g. p&lt;0.05) rechazamos la hipótesis nula, es decir, hay evidencia de relación entre \\(X\\) y \\(Y\\). Si el valor-p es mas grande (e.g. &gt;0.05), no se rechaza la hipotesis nula. Otro estadístico a tener en cuenta es el estadístico \\(R^{2}\\), comunmente conocido como coeficiente de proporcionalidad. Esta se usa como una manera alternativa de ver que tan bien ajustado está el modelo. \\(R^{2}\\) usualmente toma valores entre 0 y 1, y es independiente de la escala de \\(Y\\). El coefiente de proporcionalidad frecuentemente se calcula como: \\[R^{2} = \\frac{TSS-RSS}{RSS} = 1 - \\frac{RSS}{TSS}\\] Donde \\(TSS = \\sum(y_{1} - \\overline{y})^{2}\\) esla suma total de todos las cuadrados. Este indice mide la varianza total de la respuesta \\(Y\\) o la cantidad de variabilidad de la respuesta antes de la regresión. Por otra parte, el RSS mide la cantidad de variabilidad que no se explica luego de realizar la regresión. Asumiendo estas definiciones podemos decir que \\(TSS - RSS\\) mide la la cantidad de variabilidad de la respues que es explicada a causa de la regresión. Por lo tanto, \\(R^{2}\\) mide la proporción de la variablidad de \\(Y\\) que es explicada por \\(X\\). Cuando \\(R^{2}\\) es cercano 1, una gran proporción de la variablidad en la respuesta es explicada por el modelo. Un valor de \\(R^{2}\\) cercano a 0 indicaría que la regresió no explica la variabilidad de la respuesta. 3.2 Regresión lineal de multiples variables Comunmente, las asociaciones entre variables no son unicamente entre dos variables. Por lo tanto, las respuestas a predicciones están dadas por más de un predictor. Para esto usualmente utilizamos una regresión de multiples variables. En este paradigma, la relacion entre cada predictor y la respuesta esta modulada por su propio parametro (i.e. pendiente). Este tipo de regresión lineal está dada por una cantidad de predictores p, y se denota matemáticamente de la siguiente manera, \\[Y ≈ β_{0} + β_{1}X_{1} + β_{2}X_{2} + … + β_{p}X_{p} + ε\\] Donde \\(X_{j}\\) representa del \\(j-ésimo\\) predictor y \\(β_{j}\\) cuantifica la asociación entre la variable y la respuesta. Esto se puede interpretar como \\(β_{j}\\) es el efecto promedio de \\(Y\\) por cada unidad de incremento en \\(X_{j}\\) cuando cuando todos los otros predictores se mantienen constantes. Excepto por la asuncion de constancia, esta definicion de pendientes no difiere marcadamente en interpretacion con relacion a lo discutido anteriormente sobre regresiones lineales. Al igual que en la regresión lineal de una varible, los coeficientes de regresión \\(β_{0}\\), \\(β_{1}\\),…, \\(β_{p}\\) son desconocidos, por lo tanto, lo que estimamos es \\(\\hatβ_{0}\\), \\(\\hatβ_{1}\\),…, \\(\\hatβ_{p}\\), lo cual hace que nuestra formula de regresión lineal cambie un poco \\[\\hat{y} = \\hatβ_{0} + \\hatβ_{1}x_{1} + \\hatβ_{2}x_{2} + … + \\hatβ_{p}X_{p} + ε\\] Por lo tanto, en regresiones multiples, existen tantas pendientes como predictores en la function. Es entonces extender, de alguna forma, el resultado de extender un modelo de regresion simple para tener en cuenta un mayor numero de variables predictoras. Hay que tambien anotar que este tipo de regresion es diferente a los modelos de regresion multivariada. En estos ultimos, existen multiples variables de respuesta, en vez de solo una como es el caso de la regresion multiple. 3.2.1 Mediciones de error para regresiones de multiples variables para los coeficientes y el modelo Similar a lo que se discutia sobre regresiones lineales simples, los parámetros en estos modelos son estimados utilizando mínimos cuadros. Sin embargo, en este caso, utilizamos la siguente formula, \\[RSS ≡ \\sum_{i = 1}^{n}(y_{i} - \\hat{y}_{i})^{2}\\] \\[RSS ≡ \\sum_{i = 1}^{n}(y_{i} - \\hatβ_{0} - \\hatβ_{1}x_{i1} - \\hatβ_{2}x_{i2} - … - \\hatβ_{p}X_{ip})^{2}\\] Los valores de \\(β_{0}\\), \\(β_{1}\\),…, \\(β_{p}\\) que minimizan la ecuación anterior son coeficientes estimados de regresión de los mínimos cuadradros multiples. Existen alternativas para estimar estos coeficientes como maxima varosimilitud. 3.2.2 Mediciones de error para regresiones de multiples variables para los coeficientes y el modelo Las regresiones multiples tambien tienen hipótesis asociadas a las relaciones entre variables. Existen dos niveles de hipotesis en este tipo de regresiones. Primero, existe una relacion general entre los predictores y la respuesta? Segundo, existe una relacion particular entre cada predictor y la respuesta? Por ahora, nos enfocaremos en el primer aspecto. El segundo aspecto es congruente con las interpretaciones discutidas en regresiones de una variable (excepto por la asuncion de constancia en la interpretacion). Nos preguntarnos por lo tanto si todos los coeficientes de la regresión son igual a cero, es decir, si \\(β_{1} = β_{2} = ... = β_{p} = 0\\). Dado esto, la hipótesis nula sería, \\(H_{0}: β_{1} = β_{2} = ... = β_{p} = 0\\) Y la hipótesis alternativa, \\(H_{\\alpha}:\\) Donde por lo menos uno de los \\(β_{j} = 0\\), Para probar estas hipótesis utilizamos el estadístico F. Este estadistico se define matemáticamente de la siguiente manera: \\[F = \\frac{(TSS - RSS)/p}{RSS/(n-p-1)}\\] Donde, \\(TSS = \\sum(y_{i} - \\overline{y})^2\\) y \\(RSS = \\sum(y_{i} - \\hat{y_{i}})^2\\). Si las asunciones del modelo son correctas entonces podemos decir que, \\[E[RSS/(n-p-1)] = \\delta^{2}\\] Además, si \\(H_{0}\\) es verdadera, entonces, \\[E[(TSS-RSS)/p] = \\delta^{2}\\] Esto quiere decir que cuando no hay una relación estadistica entre la repuesta y los predictores, el estadístico F tomaría valores cerca a 1. Sin embargo, si la hipotesis nula fuese rechazada, entocnes el estadístico F tomaría valores mayores a 1, es decir, \\(E[(TSS - RSS)/p] &gt; \\alpha^{2}\\). Igualmente, a veces queremos encontrar si los coeficientes de un subcojunto q son iguales a cero. Para el caso de la hipótesis nula esto se escribiría matemáticamente como, \\[H_{0}: β_{p-q+1} = β_{p-q+2} += … = β_{p} = 0\\] Si queremos probar una modelo que contenga todas las variables excepción de las q. Supongamos que la suma de cuadrados de los residuos para este modelo es \\(RSS_{0}\\), entonces la formar de calcular el estadístico F sería. \\[F = \\frac{(RSS_{0} - RSS)/q}{RSS/(n-p-1)}\\] Algo que debemos tener en cuenta cuando estemos realizando la elección de variables en una regresión lineal de multiples variables funciona para cada asociación entre los predicttores y la variable respuuesta, cuando p es relativamente pequeño e casi tan pequeño como n. Cuando \\(p &gt; n\\) hay más coificientes \\(β_{j}\\) para estimar que el número de observaciones que se necesita para estimar esos coeficientes. Dado este caso no podemos usar una regresión lineal multiple usando mínimos caudrados, por ello debemos usar otras alternativas, entre las cuales se encuentran: seleccion hacia adelante, seleccion desde atras y seleccion mixta, de las cuales hablaremos más adelante. 3.2.3 Interacciones entre variables Usar una de las bases de datos para ejemplificar esto. Hablar sobre como los resultados pueden cambiar cuando se usar una o varias variables; discutir esto cuando se tienen las interacciones y cuando no se tienen encuenta. 3.2.4 Comparaciones y decisiones entre modelos de multiples variables Hablar del valor p (NOTA: Ya hablé de este un poquito en regresiones de una variables). Introducir a metodos para decidir cual es el mejor modelo (AICc, AIC, BIC, adjusted R2, Mallow’s C), aunque creo que esto lo vamos expandir mas un poco mas adelante.Hablar sobre seleccion de varibles: seleccion hacia adelante, seleccion desde atras, seleccion mixta. 3.2.5 Asunsiones y posibles problemas de las regresiones lineales y cómo lidiar con ellas Hablar sobre no linearidad, correlaciones de los errores, variancia no constante en el error, datos atipicos, Punto de alto apalancamiento (high-leverage) y colinearidad. Podriamos mostrar ejemplos a acá tambien. Definiciones generales (teorico): – Simple – Multiple — Distinguir de multivariada – Asunciones – Confounders (factores de confusion: En el libro no lo explican si no hasta que se abran de Clasificaciones) – Interacciones – data augmentation (Este no lo hablan el cap de regresiones) – Mediciones de error (RMSE; MSE; MAE; etc) – Comparaciones multimodelo (AIC, AICc, BIC) Implementacion (codigo y explicacion): – Ejemplo de reg simple – Ejemplo de reg multiple – Data augmentation — Mediciones de error y comparacion multimodelo "],["clasificaciones.html", "Capitulo 4 Clasificaciones 4.1 Regresión logística 4.2 Análisis discriminante lineal 4.3 Clasificador bayesiano ingenuo 4.4 K-vecinos más cercanos 4.5 Comparación de métodos de clasificación", " Capitulo 4 Clasificaciones En muchas situaciones de la vida real, la variable respuesta es cualitativa en lugar de cuantitativa, también llamadas variables categóricas. Las clasificaciones son la manera por la cual se pueden predecir la respuesta de las variables cualitativas. Hay que tener un par de cosas en cuenta con respecto a la clasificación. La primera es que clasificar se refiere a predecir la respuesta de una variable cuantitativa para una observación, es decir, estamos clasificando esa observación a la cual se le asigna una categoría o clase, y la segunda, los métodos de clasificación predicen la probabilidad de cada categoría de una variable cualitativa. En este capitulo vamos a discutir tres métodos de clasificación: regresión logística, análisis discriminante lineal y el k-vecinos más cercanos. Independientemente de cuál de estos tres métodos utilicemos, para las clasificaciones también tenemos un set de observaciones de entrenamientos \\((x_{1}, y_{1})\\),…,\\((x_{n}, y_{n})\\), las cuales se usan para construir el clasificador. Lo que buscamos es que nuestro clasificador sea bueno para clasificar los datos de entrenamiento, al igual que en las observaciones de prueba que no fueron usadas para entrenar el clasificador. 4.1 Regresión logística Los modelos de regresión logística modelas la probabilidad de que Y pertenezca a una categoría en particular. Pero cómo se modela la relación entre \\(p(X) = Pr(Y = 1|X)\\) y Y. Para encontrar estas probabilidades podemos usar un modelo de regresión lineal. \\[p(X) = β_{0} + β_{1}X\\] No obstante, al utilizar esta ecuación, podemos obtener resultados mayores que 1 y menores que 0, por la tanto, las probabilidades deben de caer entre 0 y 1. Para evitar que \\(P(X) &lt; 0\\) para algunos valores de X y \\(P(X) &lt; 1\\) para otros valores X, debemos modelar nuestra ecuación para que nuestros resultados caigan entre 0 y 1 para todos los valores de X. En regresiones logísticas, utilizamos la función logística, la cual está dada por \\[P(X) = \\frac{e^{ β_{0} + β_{1}X }}{1 + e^{ β_{0} + β_{1}X }}\\] Para poder ajustar el modelo, utilizamos algo llamado método de máxima verosimilitud. Cuando graficamos la función logística en un plano, vamos a encontrar que va a dar una curva en forma de S. La ecuación puede ser simplificada de la siguiente manera \\[\\frac{P(X)}{1 – P(X)} = e^{ β_{0} + β_{1}X }\\] La cantidad dada por \\(p(X)/[1 – p(X)]\\) es conocida como posibilidades, y puede tomar valores entre \\(0\\) e \\(\\infty\\). Valores de posibilidades hacer de \\(0\\) e \\(\\infty\\) indica muy bajas o muy altas probabilidades, respectivamente. Si aplicamos logaritmo a ambos lados de la ecuación tendremos que \\[log(\\frac{P(X)}{1 – p(X)} = β_{0} + β_{1}X)\\] La parte de la izquierda esta ecuación es conocida como función logit, log-odds o logit, que es básicamente la transformación de \\(p(X)\\). En los modelos de regresión logística, el incremento de una unidad de X cambia los log-odds por \\(β_{1}\\), esto también se puede ver como la multiplicación de las posibilidades por \\(e^{β_{1}}\\). Note: dado que la relación entre \\(p(X)\\) y \\(X\\) no es una línea recta, \\(β_{1}\\) no corresponde al cambio de \\(p(X)\\) asociado con el incremento en una unidad en \\(X\\). 4.1.1 Estimación de coeficiente en regresiones logísticas Para el caso de las regesiones logísticas, los coeficientes \\(β_{0}\\) y \\(β_{1}\\) son desconocidos, así que los tenemos que estimar utilizando el set de datos de entrenamiento. Para esto utilizamos un método conocido como máxima verosimilitud. Este método busca encontrar un \\(\\hat{β_{0}}\\) y un \\(\\hat{β_{1}}\\) que al ser momento de ser incluidos en el modelo para \\(p(X)\\) de como resultado números entre 0 y 1. La ecuación de la función de la verosimilitud está dada por \\[l(β_{0}, β_{1}) = \\prod_{i:y_{1} = 1}p(X) \\prod_{i’:y_{i’=0}}(1-p(x_{i’}))\\] En donde los \\(β_{0}\\) y \\(β_{1}\\) que se van a elegir son aquellos que maximicen la función de la verosimilitud de los datos observados. La ecuación anterior, nos da la probabilidad de observador 0 y 1 en nuestros datos. Al igual como ya lo hemos visto en los otros modelos, para el caso de la regresión logística, podemos medir que tan precisa fue la estimación de los coeficientes por medio del error estándar. Para ello, utilizamos el estadístico z. Para el caso del estadístico z, tenemos que está asociado con \\(β_{1}\\) lo cual es igual a \\(\\hat{β_{1}}/SE(\\hat{β_{1}})\\). Con esto, podemos decir que un valor grande de z es evidencia en contra de la hipótesis nula \\(H_{0}: β_{1}=0\\), esto implicaría que la hipótesis nula es \\(p(X)=\\frac{e^{β_{0}}}{1+ e^{β_{0}}}\\). 4.1.2 Regresiones logísticas múltiples y para &gt;2 clases de respuestas Para el caso de las regresiones logísticas, estas se pueden utilizar para predecir problemas de variables binarias usan múltiples predictores. Para ello, usamos la siguiente ecuación \\[log(\\frac{p(X)}{1-p(X)}) = β_{0} + β_{1}X_{1} +…+ β_{p}X_{p}\\] Donde \\(X = (X_{1},…,X_{p})\\) indican una cantidad p de predictores. Esta ecuación se puede reescribir como \\[p(X) = \\frac{e^{ β_{0} + β_{1}X_{1}+…++ β_{p}X_{p}}}{1+ e^{β_{0} + β_{1}X_{1}+…++ β_{p}X_{p}}}\\] En este caso, utilizamos el método de máxima verosimilitud para estimar \\(β_{0}\\), \\(β_{1}\\),…, \\(β_{p}\\). Para poder explicar más a detalle esta sección, nos toca utilizar ejemplos, en especial para explicar lo de variables de confusión (confounding variables). Por otro lado, a veces necesitamos clasificar una variable respuesta que tiene mas de dos clases. Para esto usualmente usamos el análisis discriminante lineal. 4.2 Análisis discriminante lineal El análisis discriminante lineal (LDA por sus siglas en inglés, Linear Discriminant Analysis) es un método que busca determinar a qué grupo pertenece un individuo. Es decir, nosotros modelamos la distribución de los predictores X separadamente en cada una de las clases respuesta (Y), y luego usamos el teorema de Bayes para encontrar lo estimados para \\(Pr(Y = k|X=x)\\). Cuando se asume una distribución normal, este modelo se comparta de una manera similar a la regresión logística. 4.2.1 Teorema de Bayes para las clasificaciones Cuando queremos clasificar una observación en una de las K clases, donde \\(K \\ge 2\\). Es decir, la respuesta categórica de la variable Y puede tomar K valores distintos. La función de densidad de X nos ayuda a encontrar cuando una observación es de la clase kth, esta se denota como \\(f_{k}(X) ≡ Pr(X = x|Y = k)\\). Esto quiere decir que si \\(f_{k}(x)\\) es relativamente grande, la probabilidad de que uno observación pertenezca a clase kth es \\(X ≈ x\\), es decir, es alta. Por otro lado, si \\(f_{k}(x)\\) es bajo, la probabilidad de que kth sea \\(X ≈ x\\) es baja también. Por esto, el Teorema de Bayes dice que \\[Pr(Y = k|X = x) = \\frac{\\pi_{k}f_{k}(x)}{\\sum_{l=1}^{K}f_{l}(x)}\\] En donde \\({\\pi_{k}}\\) representa la probabilidad a priori de observar una observación elegida al azar que provenga de kth. \\({\\pi_{k}}\\) puede estimarse fácilmente si tenemos una muestra aleatoria de Ys de la población. Nota: Nos referimos a \\(p_{k}(x)\\) como la probabilidad posterior de una observación de \\(X = x\\) de pertenecer a la clase \\(k\\)th. Esto quiere decir la probabilidad de que la observación pertenezca a la clase \\(k\\)th \\(dada\\) el valor del predictor para esa observación 4.2.2 Análisis discriminante lineal para \\(p = 1\\) Asumamos que solo tenemos un predictor, es decir, \\(p = 1\\). Para obtener un estimado de \\(f_{k}(x)\\) usamos la ecuación anterior para poder estimar \\(p_{k}(x)\\). Lo que buscamos es clasificar una observación a la clase en la cual \\(p_{k}(x)\\) es mas alto. Asumamos de nuevo \\(f_{k}(x)\\) es normal o Gausiana. Con un solo estimador, la densidad normal toma la forma de \\[f_{k}(x) = \\frac{1}{\\sqrt{2\\pi}\\delta_{k}}exp(-\\frac{1}{2\\delta_{k}^{2}}(x-\\mu_{k})^2)\\] Donde \\(\\mu_{k}\\) y \\(\\delta_{k}^{2}\\) son la media y la varianza de los parámetros para las kth clases. Asumamos que la varianza esta compartida entre todas las K clases, es decir, \\(\\delta_{1}^{2} = …=\\delta_{1}^{K}\\), lo cual se puede denotar como \\(\\delta^{2}\\), ahora reemplacemos algunos términos de las dos ecuaciones anteriores \\[p_{k}(x) = \\frac{\\pi_{k}\\frac{1}{\\sqrt{2\\pi}\\delta}exp(-\\frac{1}{2\\delta^{2}}(x-\\mu_{k})^2)}{\\sum_{l=1}^{K}\\pi_{l}\\frac{1}{\\sqrt{2\\pi}\\delta}exp(-\\frac{1}{2\\delta^{2}}(x-\\mu_{l})^2)}\\] Esta ecuación puede ser simplificada y cancelaciones, pero primero debemos tener en cuenta que para clasificar el valor de \\(X = x\\), neces itamos encontrar la clases donde la función \\(p_{k}(X)\\) sea mayor. Ahora, apliquemos logaritmos, simplifiquemos y cancelemos algunos términos que no depende de k de la ecuación anterior. Con esto podemos ver que es equivalente a asignar x a la clase con el puntaje discrimante más alto \\[\\delta_{k}(x) = x ⋅ \\frac{\\mu_{k}}{\\delta^{2}} - \\frac{\\mu_{k}^{2}}{2\\delta^{2}} + log(\\pi_{k})\\] Aquí podemos notar que \\(\\delta_{k}(x)\\) es una función linear de x. Además, si hay \\(K = 2\\) clases y \\(\\pi_{1} = \\pi_{2} = 0.5\\), podemos decir que el límite de decisión es \\[x = \\frac{\\mu_{1} + \\mu_{2}}{2}\\] En la práctica, no sabemos cual es el valor de algunos parámetros, (\\(\\mu_{K}\\), \\(\\pi_{k}\\), \\(\\delta^{2}\\)), pero tenemos los datos de entrenamiento, los cuales podemos usar para estimar esos parametros. Las ecuaciones para estimar esos parámetros estas dadas por las siguiente escuaciones, comenzando con la media \\[\\hat\\mu_{k} = \\frac{1}{n_{k}} \\sum_{i:y_{i} = k}x_{i}\\] \\(\\hat\\pi_{k}\\), la cual es la probabilidad a priori de que una observación pertenezca a la kth clase, está dada por \\[\\hat\\pi_{k} = \\frac{n_{k}}{n}\\] La varianza está dada por \\[\\hat\\delta_{k} = \\sum_{k=1}^{K}\\frac{n_{k} - 1}{n - K} ⋅ \\hat\\delta_{k}^{2}\\] Para estas tres ecuaciones, n denota el número total de observaciones de entrenamiento y \\(n_{k}\\) el número de observaciones de entrenamiento en la clase kth. 4.2.3 Análisis discriminante lineal para \\(p &gt; 1\\) Ahora, asumamos que nuestro clasificador LDA tiene multiples predictores. Para esto tendríamos que asumir que \\(X = (X_{1}, X_{2},...,X_{p})\\) tiene una distribución Gausiana multiple, con una media vectorial para una clase específica y una matriz de covarianza común. Nota: la distribució Gausiana multivariada asume que cada predictor individual tiene una distribución normal unidimensional con algún grado de correlación entre pares de predictores. La densidad Gausiana mulvariada se define como \\[f(x) = \\frac{1}{(2\\pi)^{p/2}|\\sum|^{1/2}}exp(-\\frac{1}{2}(x - \\mu)^{T}\\sum^{-1}(x - \\mu))\\] Para esto caso, se asume que el clasificador LDA escoje una observación de la clase kth de una distribució Gausiana multivariada \\(N(\\mu_{k}, \\sum)\\), donde \\(\\mu_{k}\\) es el vector de una media clase específica, y \\(\\sum\\) es una matriz de covarianza que es común para todas las clases K. La función discriminante cuando \\(p &gt; 1\\) se denota como \\[\\delta_{k}(X) = x^{T}\\sum^{-1}\\mu_{k}-\\frac{1}{2}\\mu_{k}^{T}\\sum^{-1}\\mu_{k} + log\\pi_{k}\\] Al igual que en otros clasificadores, tenemos que estimar los parámetrros que son desconocidos \\(\\mu_{1},...,\\mu_{k}\\), \\(\\pi_{1},...,\\pi_{k}\\), \\(\\sum\\)), las formulas para hallar estos parámetros son parecidas a las que vimos anteriormente para LDA de un solo predictor. Asimismo, para el caso de LDA buscamos que el modelo tengo una tasa de error baja al momento de clasificar, sin embargo, hay un par de salvedades Los erros de entrenamiento usualmente van a ser más bajo que los erros de prueba. En otras palabras, entre más alta seta se la relación de los parámetros p con el número de muestras n, más posibilidad hay de que el sobreajuste tenga un rol en el error. El clasifcador nulo va a tener una tasa de error que solo es un poquito más alta que la tasa de error del set de entrenamiento de LDA. Cuando estamos corriendo nuestro LDA nos podemos encontrar con dos tipos de error: Falso positivo: que son la fracción de ejemplos negativos que fueron clasificados como positivos. Falso negativo: que son la fracción de ejemplos positivos que fueron clasificados como negativos. Durante nuestro análisis de LDA lo que queremos es reducir la tasa del error lo más posible, para esto buscamos encontrar el punto en el cual el error general, el de falsos negativos y el de falsos positivos sea el más bajo. Una de las gráficas más populares para visualizar dos tipos de errores al mismo tiempo en la curva ROC (por sus siglas en inglés, receiver operating characterictics). Con esta podemos ver qué efectivo ha isdo nuestor clasificador, el cual resume todos los posibles umbrales, en una parte de la curva conocida como area bajo la curva o AUC (por sus siglas en inglésl area under the curve); entre más alto el AUC mejor. 4.2.4 Análisis discrimimante cuadrático Usualmente usamos el análisis discrimimante cuadrático o QDA (por sus siglas en inglés; quadratic disminant analysis) cuando las observaciones dentro de clase son elegidas de una distribución Gausiana multivariada con una media clase-específica y una matriz de covarianza común para todas las clases K. QDA asume que cada calse tiene su propia matriz de covarianza. Es decir, cada observación de de la clase kth está por la forma \\(X \\sim {\\sf N}(\\mu_{k}, \\sum_{k})\\), donde \\(\\sum_{k}\\) es una matriz de covarianza para la clase kth. Bajo estas asunciones, el clasificador de Bayes asigna para una observación \\(X = x\\) a una clase donde \\(\\delta_{k}(x)\\) sea más alto, esto está dado por \\[\\delta_{k}(x) = -\\frac{1}{2}(x-\\mu_{k}^{T})\\sum_{k}^{-1}(x-\\mu_{k}^{T})+log\\pi_{k}-\\frac{1}{2}log|\\sum_{k}|\\] QDA estima una matriz de varianza separada para cada clase, para un total de \\(Kp(p+1)/2\\) parámetros. Esto hace que QDA sea un clasificador más flexible que LDA. Usualmente se recomienda utilizar QDA si el set de entrenaminto es grande, para que a así la varianza del clasificador no sea un problema o por si la asunción de tener una matriz de covarianza común para las cada clase K no se puede obtener. 4.3 Clasificador bayesiano ingenuo El clasificador bayesiano ingueno o naive Bayes asume que todas las características son independientes en cda clase. Este es particularmente útil cuando p es muy grande y otros métodos como LDA y QDA no son capaces de manejar tantos datos. El naive Bayes gausiana sume que \\(\\sum_{k}\\) es diagonal, es decir \\[\\delta_{k}(x) = \\frac{1}{2}\\sum_{j=1}^{p}[\\frac{(x_{j} - \\mu_{kj})^{2}}{\\delta_{kj}^{2}}] + log\\pi_{k}\\] Asimismo, el naive Bayes se puede usar para vectores con caracteríticas mixtas (cualitativas y cuantitativas). Si \\(X_{j}\\) es cualitativa se puede reemplezar \\(f_{kj}(x_{j})\\) con la función de masa de probabilida (histograma) sobre categorías discretas. Nota: a pesar de las asunciones, el naive Bayes usualmente produce bueno resultados de clasificación. 4.4 K-vecinos más cercanos En capítulos anteriores hablamos brevemente sobre K-vecinos más cercanos o KNN (por sus siglas en inglés, k-nearest neighbors). Para hacer predicciones para un observación de \\(X = x\\), las observaciones K de entrenamiento que son cercanas a x son identificadas. Luego, X es asignada a una de las clases cuya plurarlidad corresponda a una de las observaciones a las que pertenece. Es decir que KNN es una método completamente no paramétrico. Este método requiere la selección de K, los vecinos más cercanos, es decir, realizamos el KNN con dos valores de \\(K: K = 1\\) y un valor de K que es escogido automaticamente usando un método llamado validación cruzada, del cual hablaremos de manera más intensiva en el próximo capítulo. Nota: KNN no hace asunsiones somre la forma de la límite de decisión, además de no decirnos cual(es) de los predictores son los más importantes. Igualmente, este método es mucho más flexible que QDA. 4.5 Comparación de métodos de clasificación Anteriormente vimos como se pueden utilizar cada uno de los métodos de clasificación, al igual de los parámetros y las asunciones que tienen en cuenta. Sin embargo, cada uno de estos se puede utilizar dependiendo de lo que estemos buscando. Aquí vamos a dar en resumen de que implicada cada uno de estos métodos. La regresión logística es ampliamente usada como la clasificación, pero en particular cuando se tiene que \\(k = 2\\). LDA es útil cuando n es pequeño o cuando las calses están bien separadas, y las asuncions gausianas son razonables. Además, cuando \\(k &gt; 2\\). Naive Bayes es particularmente útil cuando p es muy grande. "],["métodos-de-remuestreo.html", "Capitulo 5 Métodos de remuestreo 5.1 Validación cruzada 5.2 Boopstrap (o arranque)", " Capitulo 5 Métodos de remuestreo Los métodos de remuestreo son de las herramientas más valiosas en la estadística moderna, dado que esta elije muestras del set de prueba y reajustando el modelo de interés de cada muestra con el fin de obtener información adicional sonre el modelo que ajustamos que de otro modo no estaría disponible con solo ajustar el modelo una vez usando las datos de entrenamiento. En este capítulo hablaremos sobre dos de los métodos de remuestreo más usados, validación cruzada y arranque/bootstrap. Normalmente usamos validación cruzada para estimar el erros de prueba asociado a un método de aprendizaje estadístico particular o para elegirr el nivel apropiado de flexibilidad. Mientras que bootstrap ayuda obtener una medida de precisión de los parámetros estimados o de un método de aprendizaje estadístico particular. Estos dos métodos estiman predicciones de error par los set de prueba, para la desviación estándar y el sesgo de los estimados de nuestros parámetros. 5.1 Validación cruzada Antes de comenzar, recordemos un par de conceptos que vamos usar exhaustivamente a lo largo de este capítulo. El error de prueba es el error promedio que resulta de usar uno de los métodos de aprendizaje estadístico para predecir la respuesta en una nueva observación, uno que no fue usada en el método de entrenamiento. Por otro lado, el error de entrenamiento se puede calcular aplicando el método de aprendizaje estadístico sobre las observaciones usadas en su entrenamiento. Nota: el error de entrenamiento usualmente sobreestima el error de prueba. 5.1.1 Conjunto de validación Al momento de estimar nuestro error de prueba asociado con el ajuste de nuestro método estadístico de interés en un conjuntos de observaciones, podemos separar nuestras observaciones en un un conjunto de entrenamiento y un conjunto de validación. En donde el modelo se ajusta utilizando el set de entrenamiento, y el modelo ajustado se usa para predecir la respuesta para las observaciones del conjunto de validación. El resultado de error del conjunto de validación nos da un estimado del error de prueba. Normalmente, esto se evalúa utilizando MSE en el caso de una respuesta cuantitativa y una tasa de clasificación errónea en el caso de una respuesta cualitativa (discreta). Aunque este método es ampliamente utilizado, hay algunas debilidades que tenemos que tener en cuenta: El estimado de validación del error de prubea puede ser altamente variable, lo cual depende de qué observaciones son incluídas en el set de entrenamiento y cuales son incluídas en el conjunto de validación. En este método solo se incluye un subconjunto de las observaciones, las cuales se utilizan para ajustar el modelo. El error del set de validación usualmente tiende a sobreestimar el error de prueba para el modelo que se ajusta para todo el set de datos. 5.1.2 Validación cruzada dejando un elemento fuera (LOOCV) La validación cruzada dejando un elemento fuera (LOOCV por sus siglas en inglés, leave-one-out cross-validation) es muy similar al conjunto de validación, pero trata de resolver la resolver las debilidades que este tiene. Este tipo de validación cruzada solo usamos una sola observación \\((x_{1}, y_{1})\\) para el set de validación, y el resto de observaciones \\({(x_{2}, y_{2}),...,(x_{n}, y_{n})}\\) se usan para el set de entrenamiento. Dado que \\((x_{1}, y_{1})\\) no fue usada para ajustar el proceso, \\(MSE_{1} = (y_{1} - \\haty_{1})^{2}\\) provee una aproximación del estimado no sesgado para el error de prueba. No obstante, \\(MSE_{1}\\) es un estimado muy variable, dado que estimado apartir de una sola observación \\((x_{1}, y_{1})\\). 5.1.3 Validación cruzada de K-interaciones (k-fold CV) 5.1.4 Sesgo y varianza para validación cruzada de K-interaciones 5.1.5 Validación cruzada en problemas de clasificación 5.2 Boopstrap (o arranque) "],["selección-de-modelos-lineares-y-regularización.html", "Capitulo 6 Selección de modelos lineares y regularización 6.1 Selección de subconjuntos 6.2 Métodos de contracción 6.3 Métodos de reducción dimensiones 6.4 Consideraciones en dimensiones altas", " Capitulo 6 Selección de modelos lineares y regularización 6.1 Selección de subconjuntos 6.2 Métodos de contracción 6.3 Métodos de reducción dimensiones 6.4 Consideraciones en dimensiones altas "],["métodos-basados-en-árboles.html", "Capitulo 7 Métodos basados en árboles 7.1 lightGBM 7.2 XGboost", " Capitulo 7 Métodos basados en árboles 7.1 lightGBM 7.2 XGboost "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
