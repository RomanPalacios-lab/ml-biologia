[["index.html", "Introducción al uso de machine learning en biología Capitulo 1 Una introducción breve a Machine Learning", " Introducción al uso de machine learning en biología Jhan C. Salazar y Cristian Román-Palacios 2023-08-10 Capitulo 1 Una introducción breve a Machine Learning El machine learning es una de las herramientas que más se aplica en diferentes partes de nuestra vida diaria. Por ejemplo, los mecanismos de predicción de palabras en su celular, detección de spam en el correo, predicciones de estado del tiempo, entre otros, estan cercanamente relacionados con procesos incluidos en machine learning. Sin embargo, muy pocas personas conocen cómo utilizar perspectivas de machine learning, ya sea por miedo o desconocimiento a la programación, o simplemente, porque mucha de la información se encuentra en otro idioma, usualmente, en inglés. Con este libro, buscamos dar una breve introducción al machine learning y su aplicación en el idioma español, con ejemplos en analisis de datos biologicos. Como aclaración, el que los ejemplos que se usaran a lo largo del libro estaran enfocados en investigaciones recientes en biológia no significa que no puedan ser aplicados a otras áreas de estudio. Este libro va dirigido a todas las personas interesadas en aprender a usar machine learning en su investigaciones, sin importar en que niveles de su formación académica se encuentren o que trabajen en la academio o en la indrustria. Este documento está pensado para lectores que tengan o no conocimiento previo en programación. El foco principal de este libro no es sólo enseñar cómo utilizar y entender qué es machine learning, si no hacer accesible su uso para personas de habla hispana. Este libro inicia con una introducción a machine learning, pasa por regresiones lineales, aspectos de clasificación, y termina con introducciones cortas a modelos alternativos y más complejos de regresión y clasificación. Cada uno de los capítulos revisa tando el componente práctico como el teórico del tema principal a tratar. La discusión teórica incluye detalles generales sobre la fundamentación de algoritmos y su uso en diferentes contextos. La implementación práctica incluye estudios de casos basados en publicaciones recientes por autores latinoamericanos. En general, este libro pretende una exposición tanto a aspectos generales de machine learning en su teoría y práctica, así como también al uso directo en el análisis de datos biológicos. Existe una variedad de lenguajes de programación que permiten implementar algoritmos de machine learning. En general, el componente práctico de este libro estará enfocado en ilustrar el uso de esta perspectiva analitica utilizando el lenguaje de programacion R. Esta herramientas es de código abierto, gratuita, y tiene asociada una amplia red de usuarios y desarrolladores que se encuentran en constante interacción y producción de conocimiento. Como alternativa R están python, julia, matlab, entre otros. Estos lenguages también permiten el análisis de datos en una aproximación de machine learning y son alternativas ideales para quienes tengan intenciones de explorar de forma práctica el componente teórico de este documento. Sin embargo, para quienes consultan el libro y no tienen experiencia en programación en R, el primer capitulo se enfoca en introducir R como el lenguaje para usos subsecuentes en los componentes prácticos del documento. Además de nuestro libro, existen diferentes recursos en español que tratan diferentes aspectos de machine learning en R y otros languajes de programación. Por ejemplo, en su libro, Rafael A. Irizarry da una breve introduccion a R en el contexto de ciencia de datos. R Para ciencia de datos, traducido del inglés, también es un excelente recurso introductorio tanto a R como a machine learning. Aunque estos recursos (y otros) se enuentran en español, los documentos existentes son (1) traducciones literales a textos originalmente escritos en inglés, (2) tienen poco enfasis en machine learning por ser pensados en el contexto de data science, o (3) no tienen una aplicacion directa en biologia. Por lo tanto, con este documento propendemos a integrar aspectos básicos de machine learning en el contexto actual de biología latinoamericana, mientras resaltamos el trabajo investigativo en la región. "],["qué-es-machine-learning.html", "Capitulo 2 ¿Qué es Machine Learning? 2.1 Tipos de machine learning 2.2 Definiciones relevantes a machine learning 2.3 Tipos de particiones de datos en machine learning 2.4 Introducción a los artículos y datasets que se usarán en este librillo", " Capitulo 2 ¿Qué es Machine Learning? El enfoque principal de este libro es exponer el uso de herramientas de machine learning para responder preguntar en biología. Sin embargo, aún no se ha definido formalmente que es machine learning. En pocas palabras, machine learning se refiere al uso de análisis estadísticos para hacer predicciones o inferencias sobre un problema en particular utilizando particiones específicas del conjunto de datos. Por lo tanto, el aspecto clave que distingue en general la práctica de machine learning respecta al uso de secciones de los datos con el objetivo de describir explícita y finamente el comportamiento y la generalización de los modelos. Actualmente, las aplicaciones de machine learning se encuentran varios ámbitos demuestra vida diaria. Por ejemplo, cuando hablamos a nuestro celular para interactuar con Alexa (Amazon), Siri (Apple) o Google Maps, modelos entrenados utilizando un paradigma de machine learning permite que aquellas palabras que enunciamos sean interpretadas por el equipo (e.g., celular, computador) tras algunos pasos de codificación (e.g., creacion de matrices). Igualmente, Google Maps colecta datos de tráfico desde el punto en el que estamos al sitio en donde vamos para encontrar la ruta más rápido al lugar de destino. Como optimizar estas rutas tambien puede ser una tarea de machine learning. Así como estos ejemplos, hay cientos de situaciones que pueden ser usadas para ejemplificar el uso de machine learning en nuestra cotidianidad. 2.1 Tipos de machine learning Dentro del machine learning, los problemas estadísticos generalmente se dividen en dos categorías principales: supervisadas y no supervisadas. La primera categoría, la supevisada, se refiere a que por cada observación del predictor (\\(x\\)), hay una medida de respuesta (\\(y\\)). Por el contrario, la categoría no supervisada hace referencia a que el predictor (x) no está asociado a una respuesta (y) - no tenemos una variable respuesta que pueda supervisar nuestro análisis. A lo largo del libro nos vamos a enfocar principalmente en la categoría de aprendizaje supervisado. Por otro lado, tambien se resalta que existen otras alternativas de aprendijaze en este tipo de sistemas (e.g. aprendizaje de refuerzo). Sin embargo, la ubicacion de estas aproximaciones es un poco mas ambigua con respecto a las dos principales discutidas en esta seccion. data &lt;- tibble::tibble(from = c(&quot;Machine Learning&quot;, &quot;Machine Learning&quot;, &quot;Supervised Learning&quot;, &quot;Supervised Learning&quot;, &quot;Unsupervised Learning&quot;, &quot;Unsupervised Learning&quot;), to = c(&quot;Supervised Learning&quot;, &quot;Unsupervised Learning&quot;, &quot;Classification&quot;, &quot;Regression&quot;, &quot;Clustering&quot;, &quot;Dimensionality reduction&quot;)) ggflowchart(data) 2.2 Definiciones relevantes a machine learning Al momento de utilizar modelos de machine learning debemos tener en cuenta que hay compromisos (conocidos como trade-offs en inglés). Este es el caso para la relación entre el trío de conceptos clave flexibilidad-interpretabilidad-complejidad. Entender la interacción de estos tres elementos juega un papel clave en la descripción de la generalización relativa de modelos y la definición de que tan apropiados son de acuerdo a las necesidades prácticas del investigador. Primero, la flexibilidad hace referencia a cuanto las características de los datos influencia al modelo, dado esto, algunos modelos lineales son más flexibles que otros. Por lo tanto, modelos más flexibles pueden ajustarse más cercanamente a los datos que funciones inflexibles. Sin embargo, la descripción muy ajustada de un modelo a un conjunto de datos puede implicar para este mismo modelo la incapacidad de generalización en otros conjuntos de datos. Es entonces importante considerar la necesidad de describir cercanamente un conjunto de datos sin dejar a un lado el objetivo amplio de generar modelos que permitan interpretar patrones en datos que aun no se examinan (i.e., generalización). Segundo, la interpretabilidad de un model se refiere a lo fácil o difícil que es entender como las variables influencian el resultado. En un sentido amplio, se puede decir que modelos más inflexibles son mas interpretables. La flexibilidad de un modelo tiende a aumentar a medida que la interpretabilidad disminuye. Por lo tanto, modelos más complejos tienden a no ser tan facilmente interpretables. Si el objetivo de quien analiza los datos es entender que predictores influencia la respuesta (e.g. analisis supervisados), modelos mas inflexibles (y por lo tanto menos complejos) son en general preferidos. Tercero, la complejidad hacer referencia tanto a la estructura de los modelos (e.g. cajas negras) como al número de parametros que se usan en un modelo determinado. Tener en cuenta los compromisos que ocurren entre flexibilidad, interpretabilidad y complejidad es central para entender patrones generales de seleccion de modelos dentro de un contexto de machine learning. Otros tres conceptos para tener en cuenta cuando se usan modelos de machine learning son la varianza, el ruido, y el sesgo. Primero, la varianza hace referencia a la variacion intrinseca a generar predicciones con modelos. Por ejemplo, models inflexibles tienden a generar predicciones que son consistentes entre si (modelo relativamente con poca varianza). Modelos mas complejos tienden a producir predicciones mas discimiles entre si (modelo relativamente con alta varianza). Segundo, el ruido esta asociado a la variacion intrinseca a la variable de respuesta. Este aspecto es independiente al modelo y tiene en general mas relacion con errores de medicion que con otro aspecto. Tercero, el sesgo se refiere al error que se da a causa por aproximar un problema de la vida real, teniendo en cuenta el ruido. El sesgo es por lo tanto la relacion (i.e. diferencia) entre varianza y ruido. Este aspecto es relevante dado que los modelos son simplificaciones de datos y, aunque pueden estar cercanos a la realidad, siempre tendran limitaciones para llegar al modelo subyacente. Otro concepto para tomar en cuenta cuando se esta eligiendo el método de aprendizaje estadístico es la maldición de la dimensionalidad. Este patron se refiere a los problemas que se dan a causa del aumento de variables independientes cuando en un set de datos. Debido a que al aumentar el número de dimensionas al modelo le toma más tiempo al modelo para computar el método de aprendizaje. Subajuste y sobreajuste son otros conceptos para tomar en cuenta al momento de elegir nuestro método de aprendizaje. El subajuste hace referencia cuando el error del set de datos de entrenamiento es grande, mientras que es dice que uno modelos está sobreajustado cuando el error del set de datos de entrenamiento es bajo. En donde el promedio del error es el resultado del uso del método de aprendizaje estadístico para predecir la respuesta de una nueva observación. Nota: usualmente, modelos muy complejos pueden causar que es modelo este sobreajustado. Al momento de elegir nuestro modelo de aprendizaje debemos de tener en cuenta dos tipos de errores, errores de entrenamiento y errores de prueba. Los errores de entrenamiento hacen referencia al error de los datos de entrenamiento, mientras que el error de prueba está asociado con el set observaciones. Algo que hay que tener en cuenta es que para las regresiones lineales y para las clasificaciones, no hay una relación entre el error de entrenamiento y el error de prueba. x = seq(0,5,length.out=6) y = -x label = c(&quot;Linear regression&quot;, &quot;Decision tree&quot;, &quot;K-nearest neightbors&quot;, &quot;Random Forest&quot;, &quot;Support Vector Machines&quot;, &quot;Neural Nets&quot;) data &lt;- cbind.data.frame(x, y, label) ggplot(data, aes(x = x, y = y, label = label)) + geom_text() 2.3 Tipos de particiones de datos en machine learning El aprendizaje de maquina es de alguna forma el resultado del uso consciente de la informacion disponible, generalmente en forma tabular. En este campo, existen dos tipos de grupos de datos. Cada uno de estos deriva directamente de los datos totales colectados durante procesos investigativos. Primero, el conjunto de datos de entrenamiento, referido en ingles como train set, se usa en general para que el o los modelos puedan patrones que estan posiblemente presentes en los datos. Este conjunto de datos usualmente representa el 70% u 80% de los datos originales. Segundo, el conjunto de datos de prueba, tambien mencionado como test set en ingles, se usa para examinar la capacidad de generalizacion en el aprendizaje inicial llevado a cabo en el conjunto de datos de entrenamiento. Este conjunto de datos representa usualmente el resto de la informacion que no se ha usado en el conjunto de datos de prueba. En pocas palabras, primero se entrena el modelo en el conjunto de datos de entrenamiento y despues de evalua su desempeño en el conjunto de datos de prueba. Estos conjuntos de datos tienen que ser conservados de forma independiente desde el principio de los analisis. Especificamente, el conjunto de datos de prueba tiene que servir como una fuente independiente de verificacion de que los patrones en el conjunto de datos de entrenamiento pueden extenderse a otros conjuntos de datos. Si se mezcla informacion entre estos conjuntos (fuga de datos o data leakeage), se pierde el sentido de este particionado. Existen otros tipos de particiones de los conjuntos de datos de entrenamiento y prueba. Sin embargo estos dos conjuntos son los mas relevantes en muchos sentidos para el campo. Otras particiones (e.g. validacion) seran discutidas en capitulos subsecuentes cuando se revise el re-muestreo. 2.4 Introducción a los artículos y datasets que se usarán en este librillo A lo largo de este librillo vamos a ilustrar ejemplos del uso de los diferentes métodos de aprendizaje estadístico utilizando set de datos que están publicados y disponibles para el público. Vamos a utilizar tres diferentes sets de datos el primero es un artículo liderado por Juan Carlos Copete y colaboradores, el cual está enfocado en entender la diversidad de comunidades de palmas en el Chocó biográficos. El segundo, fue liderado por Gustavo A. Londoño y colaboradores, en el cual este grupo de científicos buscaba entender los patrones de depredación de nidos en montañas del trópico. Por último, la tercera base de datos que vamos a usar fue liderada por Giovanny Ramirez y Jesus Orlando Rangel, en la cual estos investigadores buscaban entender la sucesión de plantas en un bosque del Chocó beogeográfico. Al final de cada uno de los capítulos vamos a tener ejemplos de cómo correr los diferentes análisis que se explican en el software R. El artículo que vamos a usar para los ejemplos de machine learning tiene como título “Diversidad de comunidades de palmas en el Chocó biogeográfico y su relación con la precipitación”. En este artículo los autores utilizan datos de precipitación en 48 transectos en comunidades de palmas a lo largo del Chocó biogeográfico en 4 localidades en Colombia y Ecuador. Para esto, Juan Carlos Copete y colaboradores tomaron datos de precipitación promedio anual, número promedio de individuos por transecto, número de especies y promedio de especies por transecto. Esto con el fin de responder a la pregunta de que si existe una relación entre la riqueza y abundancia de palmas en el Chocó biogeográfico. En resumen, los autores encontraron que una que diversidad de palmas está influenciada por la precipitación, mientras que la abundancia esta negativamente influenciada por la precipitación, en donde solo una especie – no muy abundantes – pueden sobrevivir en lugares muy húmedo. El segundo artículo que vamos a usar lleva como título “Changing patterns of nest predation and predator communities along a tropical elevation gradient” o “Patrones cambiantes de depredación de nidos y comunidades de depredadores a lo largo de un gradiente de elevación tropical” en español liderado por Gustavo A. Londoño y colaboradores. En este estudio los autores querían investigar si había cambios en los patrones y tipos de depredadores a lo largo de un gradiente altitudinal en bosque de Perú. Para esto, los autores utilizaron información sobre 2538 nidos que fueron monitoreados en el transcurso de seis años, desde el 2008 hasta el 2016. Además, durante ese mismo tiempo se tomaron fotografías y videos para cada uno de los nidos de los cuales 338 se tenía información de depredación. Igualmente, se tomaron datos de nido y composición del nido (si tenía huevos o polluelos). Los autores encontraron que a medida que la elevación aumenta la presión de depredación disminuye y l tipo de depredadores también cambia. Por último, Giovanny Ramirez y Jesus Orlando Rangel realizaron un estudio titulado “Sucesión vegetal en áreas de minería a cielo abierto en el bosque pluvial tropical del departamento del Chocó, Colombia”. En este estudio los autores se enfocaron en caracterizar comunidades vegetales en minas que han sido abandonadas en diferentes tiempos (30, 15 y 5 años de abandono) con el fin de ver como patrones de abundancia y diversidad cambian con el tiempo de recuperación en el municipio de Condoto en Chocó. Para esto, se midió la altura de la vegetación y se identificaron las especies presentes en cada sitio de muestreo, además de medir la abundancia relativa de especies y la frecuencia de especies. Los autores encontraron que la riqueza, mientras que la abundancia disminuye ha medida que el tiempo de recuperación aumenta (30 años -&gt; 15 años -&gt; 5 años). Esquemas: – Diagrama de supervisado vs no supervisado (Ok) – Esquema conceptual complejidad vs interpretabilidad (Ok) – Diagrama de tejo (TBD) – Maldicion de la dimensionalidad (TBD) – Todavía sigo buscando uno para regresión lineal, los que estan ahora son los de habíamos dicho al principi "],["capítulo-3-regresiones-lineales.html", "Capitulo 3 Capítulo 3: Regresiones lineales 3.1 Regresión lineal univariada 3.2 Regresión lineal de multiples variables", " Capitulo 3 Capítulo 3: Regresiones lineales Las regresiones lineales estan entre las herramientas más utilizadas para cuantificar y describir la asociacion entre variables o predecir los valores de una respuesta. En esta aproximacion metodologica, la respuesta en el modelo supervisado es continua. Los modelos de regresion lineal son usualmente percibidos como poco flexibles. Sin embargo, estos modelos pueden llegar a incluir niveles de flexibilidad y complejidad comparables con otros modelos usualmente vistos como mas flexibles. Los modelos lineales son un excelente punto de partida para entender métodos más avanzados, ya que, muchos de esos métodos son extensiones o casos especiales de regresiones lineales. 3.1 Regresión lineal univariada Este tipo de regresión es potencialmente la más simple que existe en su estructura. La regresion lineal univariada asume que hay una relación lineal entre el predictor \\(X\\) y la variable continua de respuesta \\(Y\\). Específicamente, este modelo asume que unicamente existe una dependencia entre \\(X\\) y \\(Y\\). Dentro de este paradigma, esta relación se representa como: \\[Y ≈ β_{0} + β_{1}X\\] En esta ecuacion, \\(β_{0}\\) y \\(β_{1}\\) representan dos parametros: intercepto y la pendiente, respectivamente. El intercepto se refiere al valor en el cual \\(x\\) es igual a \\(0\\), \\(x = 0\\). La pendiente se refiere a al cambio de \\(y\\) por una unidad en el cambio de \\(x\\). Es entonces el ángulo de la línea en el plano. Estos parametros deben ser estimados a partir de los datos, \\[(x_1, y_1), (x_2, y_2), … , (x_n, y_n)\\] donde \\(n\\) representa los pares de observaciones en el conjunto de datos, que consisten en una medida de \\(X\\) y una de \\(Y\\). Teniendo en cuenta que nuestro objetivo es el obtener los coeficientes para \\(β_{0}\\) y \\(β_{1}\\), asumiendo un ajuste a los datos de acuerdo a, \\[\\hat{y} ≈ \\hat{β}_{0} + \\hat{β}_{1}X_{i}\\] La ecuación anterior busca predecir \\(Y\\) en base al valor iésimo de \\(X\\). Con esto en mente, podemos decir entones que \\(e_{i} = y_{i} - \\hat{y}_{i}\\) es entonces la diferencia entre el valor real de cada observacion en el conjunto de datos (\\(y_{i}\\)) y el aproximado por el modelo (\\(\\hat{y}_{i}\\)). Esta diferencia es conocida como residual e identifica el ajuste del modelo con los datos. Conociendo entonces la desviacion que existe entre los valores generados por el modelo y los datos colectados, podemos entonces enfocarnos en minimizar el error (e.g. residuales) a partir de cambios en los valores de los parametros \\(\\hat{β}_{0}\\) y \\(\\hat{β}_{1}\\). 3.1.1 Mediciones de error para regresiones lineales univariadas para los coeficientes y el modelo Lo que buscamos en una regresión lineal es ajustar un modelo donde se cometa el minimo error con respecto a los datos existentes. Hay muchas maneras de buscar la cercanía de estos puntos (i.e. los del modelo y las observaciones). Uno de los métodos más usados es conocido como mínimos cuadrados. Con esto en mente, podemos definir la suma de los cuadrados del error residual (SCE o RSS, residual sum of squares), como: \\[RSS = e_{1}^{2} + e_{2}^{2} +⋯+ e_{n}^{2}\\] La cual equivale a la suma a lo largo de todas las observaciones en el set de datos de los residuales al cuadrado: \\[RSS=[(y_{1}-\\hat{β}_{0}-\\hat{β}_{1}x_{1})]^{2}+[(y_{2}-\\hat{β}_{0}-\\hat{β}_{1}x_{2})]^{2}+⋯+[(y_{n}-\\hat{β}_{0}-\\hat{β}_{1}x_{n})]^{2}\\] Usualmente utilizamos RSS para determinar la proporción de la variación total que es explicada por el modelo de regresión (\\(R^{2}\\) o coeficiente de determinación – vamos a hablar de esto un poco más adelante). Tambien notamos que cuando trabajamos con funciones se asume que la relación mas cerca a la realidad tiene un termino de error (\\(ε\\)). Dado esto nuestra ecuación lineal estaría dada en realidad por la estructura, \\[Y ≈ β_{0} + β_{1}X + ε\\] Hasta el momento hemos descrito patrones lineales en el set de datos. Sin embargo, los modelos que subyacen datos reales raramente son lineales. Esto es debido a complejidad adicional, donde variables externas pueden generar efectos sobre la estructura de relacion entre las variables focales. Por ello, la ecuación que mostramos anteriormente es la mejor aproximación lineal para encontrar la relación entre \\(X\\) y \\(Y\\). Esto implica que, dado los coeficientes del modelo son desconocidos en datos experimentales, solo podemos estimar estos parametros a partir de aproximaciones como las de minimos cuadrados, \\[\\hatβ_{1} = \\frac{\\sum_{i = 1}^{n}(x_{i} - \\overline{x})(y_{i} - \\overline{y})}{\\sum_{i = 1}^{n}(x_{i} - \\overline{x})^{2}}\\], \\[\\hatβ_{0} = \\overline{y} - \\hatβ_{1}\\overline{x}\\] Donde \\(\\overline{y} ≡ \\frac{1}{n}\\sum_{i = 1}^{n}y_{i}\\) y \\(\\overline{x} ≡ \\frac{1}{n}\\sum_{i = 1}^{n}x_{i}\\) (\\(≡\\) significa equivalente a) son medias. Por lo tanto, lo que se busca es estimar dos coeficientes desconocidos usando \\(β_{0}\\) y \\(β_{1}\\), los cuales definen directamente la línea a partir de la aproximacion de minimos cuadrados. Nota: si vemos con detenimiente esta ecuación, es una simplificación de la ecuación de RSS. Otra variable a tener en cuenta cuando estemos haciendo nuestros análisis es \\(\\mu\\) o la media. Este parametro, el cual es desconocido, puede ser aproximado a partir de la media para nuestra muestra, \\(\\hat{\\mu} = \\overline{y}\\) donde \\(\\overline{y} = \\frac{1}{n}\\sum_{i = 1}^{n}y_{i}\\). Para saber que tan precisa es la media de la muestra con respecto a la media global podemos estimar el error estándar de \\(\\hat{\\mu}\\), que se puede representar como \\(SE(\\hat{\\mu})\\), cuya formula es \\[Var(\\hat{\\mu}) = SE(\\hat{\\mu})^{2} = \\frac{\\delta^{2}}{n}\\], Donde \\(\\delta\\) es la desviación estándar para cada uno de los valores de \\(y_{i}\\) de \\(Y\\). Igualmente, \\(\\delta^{2}\\) hace referencia a la varianza del error. Para esto tenemos que asumir que el error \\(ε_{i}\\) de cada observación están no correlacionados, es decir, \\(\\delta^{2} = Var(ε)\\). Generalmente, \\(\\delta^{2}\\) es desconocida, pero podemos estimar el error estánadar de los residuos o RSE (por sus siglas en inglés residual standard error), para esto usamos la siguiente formula, $\\(RSE = \\sqrt{RSS/(n - 2)}\\) Ya teniendo el error estándar, podemos estimar el intervalo de confianza (e.g. 95%). Dentro de este rango se encuentra el valor que no conocemos para nuestro parámetro de interes con el valor definido de confianza. Para un regresión lineal, el 95% del intervalo de confianza de \\(\\hatβ_{1}\\) está dado por, \\[\\hatβ_{1} ± 2 ⋅ SE(\\hatβ_{1})\\] \\[[\\hatβ_{1} - 2 ⋅ SE(\\hatβ_{1})] , [\\hatβ_{1} + 2 ⋅ SE(\\hatβ_{1})]\\] Igualmente, para el intervalo de confianza de \\(\\hatβ_{0}\\), esta dado por una ecuación similar, \\[\\hatβ_{0} ± 2 ⋅ SE(\\hatβ_{0})\\] Cuando tenemos el error estándar, también podemos probar hipótesis en los coeficientes. La hipótesis que usualmente probamos contrastamos es la hipótesis nula que establece, \\(H_{0}\\): No hay relación entre \\(X\\) y \\(Y\\) Mientras que la hipótesis alternativa indica que, \\(H_{\\alpha}\\): Hay relación entre \\(X\\) y \\(Y\\) Matemáticamente hablando, la denotación para estas dos hipótesis sería respectivamente: \\[H_{0}: \\hatβ_{0} = 0\\] Y \\[H_{\\alpha}: \\hatβ_{1} ≠ 0\\] La pregunta que queda ahora es ¿cómo probamos (rechazamos o no) la hipótesis nula?. Para este tenemos que determinar que tan alejado \\(\\hatβ_{1}\\) es de un valor de 0. Para esto utilizamos el estadístico \\(t\\), el cual está dado por la ecuación, \\[t = \\frac{\\hatβ_{1} - 0}{SE(\\hatβ_{1})}\\], El estadístico mide el número de desvaciones estándar que \\(\\hatβ_{1}\\) se aleja de 0. En donde valores pequeños de \\(\\hatβ_{1}\\) dan evidencia de que \\(\\hatβ_{1} ≠ 0\\), es decir hay una relación entre \\(X\\) y \\(Y\\). Cuando \\(\\hatβ_{1}\\) tiene valores absolutos muchos más grande se rechaza la hipótesis nula. Es relativamente sencillo computar la probabilidad de observar un valor de \\(|t|\\) o mayor, cuando asumimos que \\(\\hatβ_{1} = 0\\). A esta probabilidad se le conoce normalmente como valor-p. Cuando el valor de p es muy pequeño (e.g. p&lt;0.05) rechazamos la hipótesis nula, es decir, hay evidencia de relación entre \\(X\\) y \\(Y\\). Si el valor-p es mas grande (e.g. &gt;0.05), no se rechaza la hipotesis nula. Otro estadístico a tener en cuenta es el estadístico \\(R^{2}\\), comunmente conocido como coeficiente de proporcionalidad. Esta se usa como una manera alternativa de ver que tan bien ajustado está el modelo. \\(R^{2}\\) toma valores entre 0 y 1, y es independiente de la escala de \\(Y\\). El coefiente de proporcionalidad usualmente se calcula como \\[R^{2} = \\frac{TSS-RSS}{RSS} = 1 - \\frac{RSS}{TSS}\\] Donde \\(TSS = \\sum(y_{1} - \\overline{y})^{2}\\), en otras palabras, la suma total de todos las cuadrados, el cual mide la varianza total de la respuesta \\(Y\\), también podemos definirlo como la cantidad de variabilidad de la respuesta antes de la regresión, mientras que RSS mide la cantidad de variabilidad que no se explica luego de realizar la regresión. Con esto podemos decir que \\(TSS - RSS\\) mide la la cantidad de variabilidad de la respues que es explicada a causa de realizar la regresión. \\(R^{2}\\) mide la proporción de la variablidad de \\(Y\\) que es explicada usando \\(X\\). Cuando \\(R^{2}\\) es cercano 1 indica que una gran proporción de la variablidad en la respuesta es explicada por la regresión. Mientras que un valor cercano a 0 indicaría que la regresió no explica la variabilidad de la respuesta. Lo cual quiere decir que el modelo lineal tiene algún problema, que el error inherente \\(\\delta^{2}\\) es muy alto o ambos. 3.2 Regresión lineal de multiples variables En la vida real, usualmente las respuestas a predicciones están dadas por más de un predictor. Para esto usualmente utilizamos una regresión de multiples variables, donde cada predictor tiene su propia pendiente. Este tipo de regresión lineal está dada por una cantidad de predictores p, y se denota matemáticamente de la siguiente manera \\[Y ≈ β_{0} + β_{1}X_{1} + β_{2}X_{2} + … + β_{p}X_{p} + ε\\] Donde \\(X_{j}\\) representa del \\(j-ésimo\\) predictor y \\(β_{j}\\) cuantifica la asociación entre la variable y la respuesta. Esto se puede interpretar como \\(β_{j}\\) es el efecto promedio de \\(Y\\) por cada unidad de incremento en \\(X_{j}\\) cuando cuando todos los otros predictores se mantienen constantes. Al igual que en la regresión lineal de una varible, los coeficientes de regresión \\(β_{0}\\), \\(β_{1}\\),…, \\(β_{p}\\) son desconocidos, por lo tanto, lo que estimamos es \\(\\hatβ_{0}\\), \\(\\hatβ_{1}\\),…, \\(\\hatβ_{p}\\), lo cual hace que nuestra formula de regresión lineal cambie un poco \\[\\hat{y} = \\hatβ_{0} + \\hatβ_{1}x_{1} + \\hatβ_{2}x_{2} + … + \\hatβ_{p}X_{p} + ε\\] Acá podemos seguir hablando de manera general sobre la matematica detrás de las regresiones lineales de varias variables, y al final del parrafo hacer un ejemplo con alguna de las bases de datos que tenemos 3.2.1 Mediciones de error para regresiones de multiples variables para los coeficientes y el modelo Similar a lo que hablamos en regresiones lineales simples, los parámetros se estiman utilizando mínimos cuadros, pero en este caso, utilizamos la siguente formula \\[RSS ≡ \\sum_{i = 1}^{n}(y_{i} - \\hat{y}_{i})^{2}\\] \\[RSS ≡ \\sum_{i = 1}^{n}(y_{i} - \\hatβ_{0} - \\hatβ_{1}x_{i1} - \\hatβ_{2}x_{i2} - … - \\hatβ_{p}X_{ip})^{2}\\] Los valores de \\(β_{0}\\), \\(β_{1}\\),…, \\(β_{p}\\) que minimizan la ecuación anterior son coeficientes estimados de regresión de los mínimos cuadradros multiples. 3.2.2 Mediciones de error para regresiones de multiples variables para los coeficientes y el modelo Hablar de RSS, el estadistico F y las hipotesis, RSE 3.2.3 Interacciones entre variables Usar una de las bases de datos para ejemplificar esto. Hablar sobre como los resultados pueden cambiar cuando se usar una o varias variables; discutir esto cuando se tienen las interacciones y cuando no se tienen encuenta. 3.2.4 Comparaciones y decisiones entre modelos de multiples variables Hablar del valor p (NOTA: Ya hablé de este un poquito en regresiones de una variables). Introducir a metodos para decidir cual es el mejor modelo (AICc, AIC, BIC, adjusted R2, Mallow’s C), aunque creo que esto lo vamos expandir mas un poco mas adelante.Hablar sobre seleccion de varibles: seleccion hacia adelante, seleccion desde atras, seleccion mixta. 3.2.5 Asunsiones y posibles problemas de las regresiones lineales y cómo lidiar con ellas Hablar sobre no linearidad, correlaciones de los errores, variancia no constante en el error, datos atipicos, Punto de alto apalancamiento (high-leverage) y colinearidad. Podriamos mostrar ejemplos a acá tambien. Definiciones generales (teorico): – Simple – Multiple — Distinguir de multivariada – Asunciones – Confounders (factores de confusion: En el libro no lo explican si no hasta que se abran de Clasificaciones) – Interacciones – data augmentation (Este no lo hablan el cap de regresiones) – Mediciones de error (RMSE; MSE; MAE; etc) – Comparaciones multimodelo (AIC, AICc, BIC) Implementacion (codigo y explicacion): – Ejemplo de reg simple – Ejemplo de reg multiple – Data augmentation — Mediciones de error y comparacion multimodelo "],["clasificaciones.html", "Capitulo 4 Clasificaciones 4.1 Regresión logística 4.2 Análisis discriminante lineal 4.3 Comparasión de métodos de clasificación", " Capitulo 4 Clasificaciones 4.1 Regresión logística 4.2 Análisis discriminante lineal 4.3 Comparasión de métodos de clasificación "],["métodos-de-remuestreo.html", "Capitulo 5 Métodos de remuestreo 5.1 Validación cruzada 5.2 Boopstrap (o arranque)", " Capitulo 5 Métodos de remuestreo 5.1 Validación cruzada 5.2 Boopstrap (o arranque) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
