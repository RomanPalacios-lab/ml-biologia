[["index.html", "Introducción al uso de machine learning en biología Capitulo 1 Una introducción breve a Machine Learning", " Introducción al uso de machine learning en biología Jhan C. Salazar y Cristian Román-Palacios 2023-08-08 Capitulo 1 Una introducción breve a Machine Learning El machine learning es una de las herramientas que más se aplica en diferentes partes de nuestra vida diaria. Por ejemplo, los mecanismos de predicción de palabras en su celular, detección de spam en el correo, predicciones de estado del tiempo, entre otros, estan cercanamente relacionados con procesos incluidos en machine learning. Sin embargo, muy pocas personas conocen cómo utilizar perspectivas de machine learning, ya sea por miedo o desconocimiento a la programación, o simplemente, porque mucha de la información se encuentra en otro idioma, usualmente, en inglés. Con este libro, buscamos dar una breve introducción al machine learning y su aplicación en el idioma español, con ejemplos en analisis de datos biologicos. Como aclaración, el que los ejemplos que se usaran a lo largo del libro estaran enfocados en investigaciones recientes en biológia no significa que no puedan ser aplicados a otras áreas de estudio. Este libro va dirigido a todas las personas interesadas en aprender a usar machine learning en su investigaciones, sin importar en que niveles de su formación académica se encuentren o que trabajen en la academio o en la indrustria. Este documento está pensado para lectores que tengan o no conocimiento previo en programación. El foco principal de este libro no es sólo enseñar cómo utilizar y entender qué es machine learning, si no hacer accesible su uso para personas de habla hispana. Este libro inicia con una introducción a machine learning, pasa por regresiones lineales, aspectos de clasificación, y termina con introducciones cortas a modelos alternativos y más complejos de regresión y clasificación. Cada uno de los capítulos revisa tando el componente práctico como el teórico del tema principal a tratar. La discusión teórica incluye detalles generales sobre la fundamentación de algoritmos y su uso en diferentes contextos. La implementación práctica incluye estudios de casos basados en publicaciones recientes por autores latinoamericanos. En general, este libro pretende una exposición tanto a aspectos generales de machine learning en su teoría y práctica, así como también al uso directo en el análisis de datos biológicos. Existe una variedad de lenguajes de programación que permiten implementar algoritmos de machine learning. En general, el componente práctico de este libro estará enfocado en ilustrar el uso de esta perspectiva analitica utilizando el lenguaje de programacion R. Esta herramientas es de código abierto, gratuita, y tiene asociada una amplia red de usuarios y desarrolladores que se encuentran en constante interacción y producción de conocimiento. Como alternativa R están python, julia, matlab, entre otros. Estos lenguages también permiten el análisis de datos en una aproximación de machine learning y son alternativas ideales para quienes tengan intenciones de explorar de forma práctica el componente teórico de este documento. Sin embargo, para quienes consultan el libro y no tienen experiencia en programación en R, el primer capitulo se enfoca en introducir R como el lenguaje para usos subsecuentes en los componentes prácticos del documento. Además de nuestro libro, existen diferentes recursos en español que tratan diferentes aspectos de machine learning en R y otros languajes de programación. Por ejemplo, en su libro, Rafael A. Irizarry da una breve introduccion a R en el contexto de ciencia de datos. R Para ciencia de datos, traducido del inglés, también es un excelente recurso introductorio tanto a R como a machine learning. Aunque estos recursos (y otros) se enuentran en español, los documentos existentes son (1) traducciones literales a textos originalmente escritos en inglés, (2) tienen poco enfasis en machine learning por ser pensados en el contexto de data science, o (3) no tienen una aplicacion directa en biologia. Por lo tanto, con este documento propendemos a integrar aspectos básicos de machine learning en el contexto actual de biología latinoamericana, mientras resaltamos el trabajo investigativo en la región. "],["qué-es-machine-learning.html", "Capitulo 2 ¿Qué es Machine Learning? 2.1 Tipos de machine learning 2.2 Definiciones relevantes a machine learning 2.3 Tipos de particiones de datos en machine learning 2.4 Introducción a los artículos y datasets que se usarán en este librillo", " Capitulo 2 ¿Qué es Machine Learning? El enfoque principal de este libro es exponer el uso de herramientas de machine learning para responder preguntar en biología. Sin embargo, aún no se ha definido formalmente que es machine learning. En pocas palabras, machine learning se refiere al uso de análisis estadísticos para hacer predicciones o inferencias sobre un problema en particular utilizando particiones específicas del conjunto de datos. Por lo tanto, el aspecto clave que distingue en general la práctica de machine learning respecta al uso de secciones de los datos con el objetivo de describir explícita y finamente el comportamiento y la generalización de los modelos. Actualmente, las aplicaciones de machine learning se encuentran varios ámbitos demuestra vida diaria. Por ejemplo, cuando hablamos a nuestro celular para interactuar con Alexa (Amazon), Siri (Apple) o Google Maps, modelos entrenados utilizando un paradigma de machine learning permite que aquellas palabras que enunciamos sean interpretadas por el equipo (e.g., celular, computador) tras algunos pasos de codificación (e.g., creacion de matrices). Igualmente, Google Maps colecta datos de tráfico desde el punto en el que estamos al sitio en donde vamos para encontrar la ruta más rápido al lugar de destino. Como optimizar estas rutas tambien puede ser una tarea de machine learning. Así como estos ejemplos, hay cientos de situaciones que pueden ser usadas para ejemplificar el uso de machine learning en nuestra cotidianidad. 2.1 Tipos de machine learning Dentro del machine learning, los problemas estadísticos se dividen en dos categorías: supervisadas y no supervisadas. La primera categoría, la supevisada, se refiere a que por cada observación del predictor (x), hay una medida de respuesta (y). Por el contrario, la categoría no supervisada hace referencia a que el predictor (x) no está asociado a una respuesta (y) - no tenemos una variable respuesta que pueda supervisar nuestro análisis. A lo largo del libro nos vamos a enfocar principalmente en la categoría de aprendizaje supervisado. 2.2 Definiciones relevantes a machine learning Al momento de utilizar modelos de machine learning debemos tener en cuenta que hay compromisos (conocidos como trade-offs en inglés). Este es el caso para la relación entre el trío de conceptos clave flexibilidad-interpretabilidad-complejidad. Entender la interacción de estos tres elementos juega un papel clave en la descripción de la generalización relativa de modelos y la definición de que tan apropiados son de acuerdo a las necesidades prácticas del investigador. Primero, la flexibilidad hace referencia a cuanto las características de los datos influencia al modelo, dado esto, algunos modelos lineales son más flexibles que otros. Por lo tanto, modelos más flexibles pueden ajustarse más cercanamente a los datos que funciones inflexibles. Sin embargo, la descripción muy ajustada de un modelo a un conjunto de datos puede implicar para este mismo modelo la incapacidad de generalización en otros conjuntos de datos. Es entonces importante considerar la necesidad de describir cercanamente un conjunto de datos sin dejar a un lado el objetivo amplio de generar modelos que permitan interpretar patrones en datos que aun no se examinan (i.e., generalización). Segundo, la interpretabilidad de un model se refiere a lo fácil o difícil que es entender como las variables influencian el resultado. En un sentido amplio, se puede decir que modelos más inflexibles son mas interpretables. La flexibilidad de un modelo tiende a aumentar a medida que la interpretabilidad disminuye. Por lo tanto, modelos más complejos tienden a no ser tan facilmente interpretables. Si el objetivo de quien analiza los datos es entender que predictores influencia la respuesta (e.g. analisis supervisados), modelos mas inflexibles (y por lo tanto menos complejos) son en general preferidos. Tercero, la complejidad hacer referencia tanto a la estructura de los modelos (e.g. cajas negras) como al número de parametros que se usan en un modelo determinado. Tener en cuenta los compromisos que ocurren entre flexibilidad, interpretabilidad y complejidad es central para entender patrones generales de seleccion de modelos dentro de un contexto de machine learning. Otros tres conceptos para tener en cuenta cuando se usan modelos de machine learning son la varianza, el ruido, y el sesgo. Primero, la varianza hace referencia a la variacion intrinseca a generar predicciones con modelos. Por ejemplo, models inflexibles tienden a generar predicciones que son consistentes entre si (modelo relativamente con poca varianza). Modelos mas complejos tienden a producir predicciones mas discimiles entre si (modelo relativamente con alta varianza). Segundo, el ruido esta asociado a la variacion intrinseca a la variable de respuesta. Este aspecto es independiente al modelo y tiene en general mas relacion con errores de medicion que con otro aspecto. Tercero, el sesgo se refiere al error que se da a causa por aproximar un problema de la vida real, teniendo en cuenta el ruido. El sesgo es por lo tanto la relacion (i.e. diferencia) entre varianza y ruido. Este aspecto es relevante dado que los modelos son simplificaciones de datos y, aunque pueden estar cercanos a la realidad, siempre tendran limitaciones para llegar al modelo subyacente. Otro concepto para tomar en cuenta cuando se esta eligiendo el método de aprendizaje estadístico es la maldición de la dimensionalidad. Este patron se refiere a los problemas que se dan a causa del aumento de variables independientes cuando en un set de datos. Debido a que al aumentar el número de dimensionas al modelo le toma más tiempo al modelo para computar el método de aprendizaje. Subajuste y sobreajuste son otros conceptos para tomar en cuenta al momento de elegir nuestro método de aprendizaje. El subajuste hace referencia cuando el error del set de datos de entrenamiento es grande, mientras que es dice que uno modelos está sobreajustado cuando el error del set de datos de entrenamiento es bajo. En donde el promedio del error es el resultado del uso del método de aprendizaje estadístico para predecir la respuesta de una nueva observación. Nota: usualmente, modelos muy complejos pueden causar que es modelo este sobreajustado. Al momento de elegir nuestro modelo de aprendizaje debemos de tener en cuenta dos tipos de errores, errores de entrenamiento y errores de prueba. Los errores de entrenamiento hacen referencia al error de los datos de entrenamiento, mientras que el error de prueba está asociado con el set observaciones. Algo que hay que tener en cuenta es que para las regresiones lineales y para las clasificaciones, no hay una relación entre el error de entrenamiento y el error de prueba. 2.3 Tipos de particiones de datos en machine learning Hablar de training and test sets 2.4 Introducción a los artículos y datasets que se usarán en este librillo A lo largo de este librillo vamos a ilustrar ejemplos del uso de los diferentes métodos de aprendizaje estadístico utilizando set de datos que están publicados y disponibles para el público. Vamos a utilizar tres diferentes sets de datos el primero es un artículo liderado por Juan Carlos Copete y colaboradores, el cual está enfocado en entender la diversidad de comunidades de palmas en el Chocó biográficos. El segundo, fue liderado por Gustavo A. Londoño y colaboradores, en el cual este grupo de científicos buscaba entender los patrones de depredación de nidos en montañas del trópico. Por último, la tercera base de datos que vamos a usar fue liderada por Giovanny Ramirez y Jesus Orlando Rangel, en la cual estos investigadores buscaban entender la sucesión de plantas en un bosque del Chocó beogeográfico. Al final de cada uno de los capítulos vamos a tener ejemplos de cómo correr los diferentes análisis que se explican en el software R. El artículo que vamos a usar para los ejemplos de machine learning tiene como título “Diversidad de comunidades de palmas en el Chocó biogeográfico y su relación con la precipitación”. En este artículo los autores utilizan datos de precipitación en 48 transectos en comunidades de palmas a lo largo del Chocó biogeográfico en 4 localidades en Colombia y Ecuador. Para esto, Juan Carlos Copete y colaboradores tomaron datos de precipitación promedio anual, número promedio de individuos por transecto, número de especies y promedio de especies por transecto. Esto con el fin de responder a la pregunta de que si existe una relación entre la riqueza y abundancia de palmas en el Chocó biogeográfico. En resumen, los autores encontraron que una que diversidad de palmas está influenciada por la precipitación, mientras que la abundancia esta negativamente influenciada por la precipitación, en donde solo una especie – no muy abundantes – pueden sobrevivir en lugares muy húmedo. Esquemas: – Diagrama de supervisado vs no supervisado – Esquema conceptual complejidad vs interpretabilidad – Diagrama de tejo – Maldicion de la dimensionalidad "],["capítulo-3-regresiones-lineales.html", "Capitulo 3 Capítulo 3: Regresiones lineales", " Capitulo 3 Capítulo 3: Regresiones lineales Regresiones lineales Las regresiones lineales son una de las herramientas más utilizadas para cuantificar una respuesta. La cual es el mejor punto de partida para entender métodos más avanzados, ya que, muchos de esos métodos son extensiones de regresiones lineales. Regresión lineal univariada Este tipo de regresión es la más simple que existe, y como su nombre bien lo indica asume que hay una relación lineal entre “X” y “Y”, donde “Y” es se puede predecir solamente usando el predictor “X”. Esta relación se representa con la función: Y ≈ β0 + β1X Donde β0 y β1 son dos constantes desconocidas que representan el intercepto y la pendiente de la función, los cuales a su vez son conocidos como coeficientes o parámetros. Sin embargo, en la vida real, no conocemos cual es el valor real de β0 y β1, por ello, tenemos que usar los datos para estimar los coeficientes: (x1, y1), (x2, y2), … , (xn, yn) Donde n representa pares de observaciones, que consisten en una medida de X y una de Y, teniendo nuestro objetivo es obtener los coeficientes para “β” ̂0 y “β” ̂1 en donde el modelo lineal se ajuste lo mejor posible a los datos disponibles, por tanto, nuestra ecuación lineal sería: ŷ ≈ “β” ̂0 + “β” ̂1Xi La ecuación anterior busca predecir Y en base al valor iésimo de X. Con esto en mente, podemos decir entones que ei = yi – ŷi, lo cual representa el iésimo residual (la diferencia entre el valor observado de i y el valor de i en la respuesta predicha en el modelo lineal). Con todo esto, buscamos encontrar un intercepto “β” ̂0 con una pendiente “β” ̂1 que resulte en la línea más cerca posible a los datos que utilizamos en nuestro modelo. Hay muchas maneras de buscar la cercanía de estos puntos, uno de los métodos más usados es conocido como mínimos cuadrados. Con esto en mente, podemos definir la suma de los cuadrados del error residual (SCE o RSS – residual sum of squares – aquí lo vamos a llamar RSS), como RSS = e_1^2+ e_2^2+⋯+ e_n^2 La cual equivale a RSS = 〖(y_1- β ̂_0- β ̂_1 x_1)〗^(2 )+ 〖(y_2- β ̂_0- β ̂_1 x_2)〗^(2 )+⋯+〖(y_n- β ̂_0- β ̂_1 x_n)〗^(2 ) Usualmente utilizamos RSS para determinar la proporción de la variación total que es explicada por el modelo de regresión (R2 o coeficiente de determinación – vamos a hablar de esto un poco más adelante). Cuando trabajamos con funciones, asumimos que la relación mas cerca a la realidad tiene un termino de error, dado esto nuestra ecuación lineal estaría dada por: Y ≈ β0 + β1X + ε Para recapitular, “β” ̂0 es el intercepto, el cual se refiere al valor de Y cuando X = 0, “β” ̂1 es la pendiente, que hace referencia al incremento de Y que está asociado con el cambio de una unidad de X, mientras que el valor de ε es el error que está presente cuando se corre este modelo lineal. Algo que no hemos mencionado hasta ahora, es que, posiblemente, una verdadera relación nunca es linear, porque puede haber otras variables que causan que haya variación en Y. Por ello, la ecuación que mostramos anterior mente es la mejor aproximación lineal para encontrar la verdadera relación entre X y Y. Definiciones generales (teorico): – Simple – Multiple — Distinguir de multivariada – Asunciones – Confounders (factores de confusion) – Interacciones – data augmentation – Mediciones de error (RMSE; MSE; MAE; etc) – Comparaciones multimodelo (AIC, AICc, BIC) Implementacion (codigo y explicacion): – Ejemplo de reg simple – Ejemplo de reg multiple – Data augmentation — Mediciones de error y comparacion multimodelo "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
